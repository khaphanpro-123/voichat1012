# ğŸ—ï¸ ARCHITECTURE CHO PRODUCTION SCALE

## ğŸ“Š YÃŠU Cáº¦U Há»† THá»NG

**Scale:**
- Nhiá»u users (1,000 - 100,000+ users)
- Má»—i user cÃ³ nhiá»u documents (10-1,000 documents)
- Documents lá»›n (1MB - 50MB, 1,000 - 100,000 words)
- Concurrent uploads (10-100 users cÃ¹ng lÃºc)

**Challenges:**
- âŒ Timeout (documents lá»›n xá»­ lÃ½ lÃ¢u > 60s)
- âŒ Rate limit (quÃ¡ nhiá»u logs)
- âŒ Memory (nhiá»u documents cÃ¹ng lÃºc)
- âŒ Cost (Railway/Vercel cÃ³ giá»›i háº¡n)

---

## ğŸ¯ GIáº¢I PHÃP KHUYáº¾N NGHá»Š: ASYNC QUEUE ARCHITECTURE

### Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser   â”‚
â”‚  (Upload)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 1. Upload file
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Vercel (Frontend + API)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  /api/upload-document-async                  â”‚  â”‚
â”‚  â”‚  - Validate file                             â”‚  â”‚
â”‚  â”‚  - Upload to S3/Cloudflare R2                â”‚  â”‚
â”‚  â”‚  - Create job in MongoDB                     â”‚  â”‚
â”‚  â”‚  - Push to Redis queue                       â”‚  â”‚
â”‚  â”‚  - Return job_id immediately                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ 2. Push to queue
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Redis Queue (Upstash)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Queue: document_processing                  â”‚  â”‚
â”‚  â”‚  - job_id                                    â”‚  â”‚
â”‚  â”‚  - user_id                                   â”‚  â”‚
â”‚  â”‚  - file_url (S3)                             â”‚  â”‚
â”‚  â”‚  - priority                                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ 3. Worker pulls job
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Railway Worker (Python)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Worker Process (Celery/RQ)                  â”‚  â”‚
â”‚  â”‚  - Pull job from queue                       â”‚  â”‚
â”‚  â”‚  - Download file from S3                     â”‚  â”‚
â”‚  â”‚  - Process document (no timeout!)            â”‚  â”‚
â”‚  â”‚  - Save results to MongoDB                   â”‚  â”‚
â”‚  â”‚  - Update job status                         â”‚  â”‚
â”‚  â”‚  - Send webhook/notification                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ 4. Poll status
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Frontend (Polling)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  GET /api/job-status/{job_id}                â”‚  â”‚
â”‚  â”‚  - Poll every 2 seconds                      â”‚  â”‚
â”‚  â”‚  - Show progress bar                         â”‚  â”‚
â”‚  â”‚  - Display results when done                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ IMPLEMENTATION CHI TIáº¾T

### 1. File Storage (S3/Cloudflare R2)

**Táº¡i sao cáº§n:**
- Vercel cÃ³ giá»›i háº¡n request size (4.5MB)
- Railway cÃ³ giá»›i háº¡n memory
- Cáº§n lÆ°u file Ä‘á»ƒ retry náº¿u fail

**Chá»n service:**

| Service | Free Tier | Pricing | Khuyáº¿n nghá»‹ |
|---------|-----------|---------|-------------|
| AWS S3 | 5GB | $0.023/GB | âœ… Standard |
| Cloudflare R2 | 10GB | $0.015/GB | âœ…âœ… Ráº» hÆ¡n |
| Vercel Blob | 500MB | $0.15/GB | âš ï¸ Äáº¯t |

**Implementation:**

```typescript
// lib/storage.ts
import { S3Client, PutObjectCommand } from "@aws-sdk/client-s3"

const s3 = new S3Client({
  region: process.env.AWS_REGION,
  credentials: {
    accessKeyId: process.env.AWS_ACCESS_KEY_ID!,
    secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY!,
  },
})

export async function uploadFile(
  file: File,
  userId: string
): Promise<string> {
  const key = `documents/${userId}/${Date.now()}-${file.name}`
  
  await s3.send(new PutObjectCommand({
    Bucket: process.env.S3_BUCKET!,
    Key: key,
    Body: Buffer.from(await file.arrayBuffer()),
    ContentType: file.type,
  }))
  
  return `https://${process.env.S3_BUCKET}.s3.amazonaws.com/${key}`
}
```

---

### 2. Queue System (Redis/Upstash)

**Táº¡i sao cáº§n:**
- Decouple upload vÃ  processing
- Handle concurrent requests
- Retry mechanism
- Priority queue

**Chá»n service:**

| Service | Free Tier | Pricing | Khuyáº¿n nghá»‹ |
|---------|-----------|---------|-------------|
| Upstash Redis | 10,000 commands/day | $0.2/100K | âœ…âœ… Serverless |
| Redis Cloud | 30MB | $0.026/GB | âœ… Standard |
| Railway Redis | $5/month | $5/month | âš ï¸ KhÃ´ng cÃ³ free |

**Implementation:**

```typescript
// lib/queue.ts
import { Redis } from "@upstash/redis"

const redis = new Redis({
  url: process.env.UPSTASH_REDIS_URL!,
  token: process.env.UPSTASH_REDIS_TOKEN!,
})

export async function enqueueJob(job: {
  jobId: string
  userId: string
  fileUrl: string
  fileName: string
  priority?: number
}) {
  // Push to queue
  await redis.lpush("document_queue", JSON.stringify(job))
  
  // Set job status
  await redis.hset(`job:${job.jobId}`, {
    status: "queued",
    createdAt: Date.now(),
  })
  
  return job.jobId
}

export async function getJobStatus(jobId: string) {
  return await redis.hgetall(`job:${jobId}`)
}
```

---

### 3. API Routes (Vercel)

**Upload API:**

```typescript
// app/api/upload-document-async/route.ts
import { NextRequest, NextResponse } from "next/server"
import { uploadFile } from "@/lib/storage"
import { enqueueJob } from "@/lib/queue"
import { v4 as uuidv4 } from "uuid"

export async function POST(request: NextRequest) {
  try {
    const formData = await request.formData()
    const file = formData.get("file") as File
    const userId = formData.get("userId") as string
    
    // Validate file
    if (!file || file.size > 50 * 1024 * 1024) {
      return NextResponse.json(
        { error: "File too large (max 50MB)" },
        { status: 400 }
      )
    }
    
    // Upload to S3
    const fileUrl = await uploadFile(file, userId)
    
    // Create job
    const jobId = uuidv4()
    await enqueueJob({
      jobId,
      userId,
      fileUrl,
      fileName: file.name,
    })
    
    // Return immediately
    return NextResponse.json({
      jobId,
      status: "queued",
      message: "Document queued for processing",
    })
  } catch (error: any) {
    return NextResponse.json(
      { error: error.message },
      { status: 500 }
    )
  }
}
```

**Status API:**

```typescript
// app/api/job-status/[jobId]/route.ts
import { NextRequest, NextResponse } from "next/server"
import { getJobStatus } from "@/lib/queue"

export async function GET(
  request: NextRequest,
  { params }: { params: { jobId: string } }
) {
  const status = await getJobStatus(params.jobId)
  
  if (!status) {
    return NextResponse.json(
      { error: "Job not found" },
      { status: 404 }
    )
  }
  
  return NextResponse.json(status)
}
```

---

### 4. Worker (Railway Python)

**Worker Process:**

```python
# worker.py
import redis
import json
import requests
from complete_pipeline_12_stages import CompletePipeline12Stages

# Connect to Redis
redis_client = redis.from_url(os.getenv("UPSTASH_REDIS_URL"))

# Initialize pipeline
pipeline = CompletePipeline12Stages()

def process_job(job_data):
    job_id = job_data["jobId"]
    file_url = job_data["fileUrl"]
    
    try:
        # Update status: processing
        redis_client.hset(f"job:{job_id}", "status", "processing")
        redis_client.hset(f"job:{job_id}", "progress", "0")
        
        # Download file from S3
        response = requests.get(file_url)
        text = extract_text_from_pdf(response.content)
        
        # Update progress
        redis_client.hset(f"job:{job_id}", "progress", "20")
        
        # Process document (no timeout!)
        result = pipeline.process_document(
            text=text,
            document_id=job_id,
            document_title=job_data["fileName"],
            max_phrases=40,
            generate_flashcards=True
        )
        
        # Update progress
        redis_client.hset(f"job:{job_id}", "progress", "90")
        
        # Save to MongoDB
        save_to_mongodb(result)
        
        # Update status: completed
        redis_client.hset(f"job:{job_id}", "status", "completed")
        redis_client.hset(f"job:{job_id}", "progress", "100")
        redis_client.hset(f"job:{job_id}", "result", json.dumps(result))
        
    except Exception as e:
        # Update status: failed
        redis_client.hset(f"job:{job_id}", "status", "failed")
        redis_client.hset(f"job:{job_id}", "error", str(e))

# Main worker loop
while True:
    # Block and wait for job (BRPOP)
    job = redis_client.brpop("document_queue", timeout=5)
    
    if job:
        job_data = json.loads(job[1])
        process_job(job_data)
```

**Dockerfile:**

```dockerfile
# Dockerfile
FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

CMD ["python", "worker.py"]
```

---

### 5. Frontend (Polling)

```typescript
// app/dashboard-new/documents-async/page.tsx
'use client'

import { useState } from 'react'

export default function DocumentsAsyncPage() {
  const [jobId, setJobId] = useState<string | null>(null)
  const [status, setStatus] = useState<any>(null)
  
  const handleUpload = async (file: File) => {
    const formData = new FormData()
    formData.append("file", file)
    formData.append("userId", "user123")
    
    // Upload and get job ID
    const { jobId } = await fetch("/api/upload-document-async", {
      method: "POST",
      body: formData,
    }).then(r => r.json())
    
    setJobId(jobId)
    
    // Start polling
    const interval = setInterval(async () => {
      const status = await fetch(`/api/job-status/${jobId}`)
        .then(r => r.json())
      
      setStatus(status)
      
      if (status.status === "completed" || status.status === "failed") {
        clearInterval(interval)
      }
    }, 2000)  // Poll every 2 seconds
  }
  
  return (
    <div>
      <input type="file" onChange={(e) => {
        if (e.target.files?.[0]) {
          handleUpload(e.target.files[0])
        }
      }} />
      
      {status && (
        <div>
          <p>Status: {status.status}</p>
          <p>Progress: {status.progress}%</p>
          
          {status.status === "completed" && (
            <div>
              {/* Display flashcards */}
              {JSON.parse(status.result).flashcards.map(card => (
                <div key={card.id}>{card.word}</div>
              ))}
            </div>
          )}
        </div>
      )}
    </div>
  )
}
```

---

## ğŸ’° CHI PHÃ Æ¯á»šC TÃNH

### Scenario: 10,000 users, 10 documents/user/month

**Storage (Cloudflare R2):**
- 10,000 users Ã— 10 docs Ã— 5MB = 500GB
- Cost: 500GB Ã— $0.015 = $7.5/month

**Queue (Upstash Redis):**
- 10,000 users Ã— 10 docs Ã— 100 commands = 10M commands
- Cost: 10M / 100K Ã— $0.2 = $20/month

**Worker (Railway):**
- 1 worker instance: $5/month
- 2 workers (for redundancy): $10/month

**Database (MongoDB Atlas):**
- M10 cluster (2GB RAM): $57/month

**Total: ~$95/month**

---

## ğŸ“Š SO SÃNH Vá»šI GIáº¢I PHÃP KHÃC

| Giáº£i phÃ¡p | Chi phÃ­ | Scalability | Complexity | Khuyáº¿n nghá»‹ |
|-----------|---------|-------------|------------|-------------|
| Sync (hiá»‡n táº¡i) | $0 | â­ | â­ | âŒ KhÃ´ng scale |
| Async Queue | $95/month | â­â­â­â­â­ | â­â­â­ | âœ…âœ…âœ… Production |
| Serverless (AWS Lambda) | $50/month | â­â­â­â­ | â­â­â­â­ | âœ…âœ… Alternative |
| Batch Processing | $20/month | â­â­â­ | â­â­ | âš ï¸ Limited |

---

## ğŸš€ ROADMAP IMPLEMENTATION

### Phase 1: MVP (1 tuáº§n)

**Má»¥c tiÃªu:** Async processing cÆ¡ báº£n

1. Setup Upstash Redis (1 giá»)
2. Setup Cloudflare R2 (1 giá»)
3. Implement upload API (2 giá»)
4. Implement worker (4 giá»)
5. Implement polling frontend (2 giá»)
6. Testing (4 giá»)

**Total: ~14 giá» (1 tuáº§n part-time)**

---

### Phase 2: Production (2 tuáº§n)

**Má»¥c tiÃªu:** Production-ready vá»›i monitoring

1. Add retry mechanism (2 giá»)
2. Add priority queue (2 giá»)
3. Add progress tracking (2 giá»)
4. Add webhook notifications (2 giá»)
5. Add monitoring (Sentry) (2 giá»)
6. Add logging (Datadog) (2 giá»)
7. Load testing (4 giá»)

**Total: ~16 giá» (2 tuáº§n part-time)**

---

### Phase 3: Scale (1 thÃ¡ng)

**Má»¥c tiÃªu:** Scale to 100K+ users

1. Multiple workers (auto-scaling)
2. CDN for file delivery
3. Database sharding
4. Caching layer (Redis)
5. Rate limiting per user
6. Admin dashboard

---

## ğŸ“‹ CHECKLIST IMPLEMENTATION

### Setup Infrastructure

- [ ] Create Cloudflare R2 bucket
- [ ] Create Upstash Redis instance
- [ ] Setup environment variables
- [ ] Test S3 upload
- [ ] Test Redis connection

### Backend Implementation

- [ ] Implement upload API
- [ ] Implement status API
- [ ] Implement worker process
- [ ] Add error handling
- [ ] Add retry logic

### Frontend Implementation

- [ ] Update upload UI
- [ ] Implement polling
- [ ] Add progress bar
- [ ] Handle errors
- [ ] Display results

### Testing

- [ ] Test with small file (1MB)
- [ ] Test with large file (50MB)
- [ ] Test concurrent uploads (10 users)
- [ ] Test error scenarios
- [ ] Load testing (100 users)

---

## ğŸ’¡ Káº¾T LUáº¬N

**Cho há»‡ thá»‘ng nhiá»u users, nhiá»u documents lá»›n:**

âœ… **KHUYáº¾N NGHá»Š: Async Queue Architecture**

**LÃ½ do:**
- KhÃ´ng bá»‹ timeout (xá»­ lÃ½ bao lÃ¢u cÅ©ng Ä‘Æ°á»£c)
- Scalable (thÃªm workers khi cáº§n)
- Better UX (progress bar, khÃ´ng block)
- Production-grade
- Chi phÃ­ há»£p lÃ½ (~$95/month cho 10K users)

**KhÃ´ng khuyáº¿n nghá»‹:**
- âŒ Sync processing (timeout, khÃ´ng scale)
- âŒ Batch processing (khÃ´ng real-time)
- âŒ Serverless only (cold start, timeout)

**Next steps:**
1. Setup infrastructure (Upstash + R2)
2. Implement Phase 1 MVP (1 tuáº§n)
3. Test vá»›i real users
4. Scale up khi cáº§n
