# ğŸš€ HÆ¯á»šNG DáºªN NHANH: Fix N-gram vÃ  Flashcard

## âœ… Táº¤T Cáº¢ FIX ÄÃƒ ÄÆ¯á»¢C ÃP Dá»¤NG!

CÃ¡c file sau Ä‘Ã£ Ä‘Æ°á»£c sá»­a:
- âœ… `ensemble_extractor.py` - Ná»›i lá»ng bigram filter + min_df=1
- âœ… `main.py` - TÄƒng max_words=50, max_flashcards=30

## ğŸ¯ BÆ¯á»šC 1: RESTART SERVER (Báº®T BUá»˜C!)

```bash
# Dá»«ng server cÅ© (náº¿u Ä‘ang cháº¡y)
Ctrl+C

# Cháº¡y láº¡i server
cd python-api
python main.py
```

**Quan trá»ng**: Náº¿u khÃ´ng restart, cÃ¡c fix sáº½ KHÃ”NG cÃ³ hiá»‡u lá»±c!

## ğŸ§ª BÆ¯á»šC 2: TEST

### Option A: Test tá»± Ä‘á»™ng (Khuyáº¿n nghá»‹)

```bash
cd python-api
python test_ngram_flashcard_fix.py
```

Káº¿t quáº£ mong Ä‘á»£i:
```
âœ… Bigrams: 10-20 found
âœ… Flashcards: 30 generated
ğŸ‰ ALL TESTS PASSED!
```

### Option B: Test thá»§ cÃ´ng qua Swagger

1. Má»Ÿ: `http://127.0.0.1:8000/docs`
2. Chá»n: `POST /api/upload-document`
3. Click "Try it out"
4. Upload file vÃ  Ä‘iá»n:
   - `max_words`: 50
   - `max_flashcards`: 30
5. Click "Execute"

### Option C: Test qua curl

```bash
curl -X POST "http://127.0.0.1:8000/api/upload-document" \
  -F "file=@test_sample.txt" \
  -F "max_words=50" \
  -F "max_flashcards=30"
```

## ğŸ“Š KIá»‚M TRA Káº¾T QUáº¢

Trong response JSON, kiá»ƒm tra:

```json
{
  "vocabulary": [
    {"word": "machine learning"},    // âœ… Bigram
    {"word": "deep learning"},       // âœ… Bigram
    {"word": "neural network"}       // âœ… Bigram
  ],
  "vocabulary_count": 47,
  "flashcards_count": 30             // âœ… 30 flashcards
}
```

**Náº¿u tháº¥y**:
- âœ… CÃ³ bigrams (tá»« cÃ³ dáº¥u cÃ¡ch) â†’ Fix thÃ nh cÃ´ng!
- âœ… flashcards_count >= 20 â†’ Fix thÃ nh cÃ´ng!

**Náº¿u váº«n tháº¥y**:
- âŒ Chá»‰ cÃ³ tá»« Ä‘Æ¡n â†’ ChÆ°a restart server
- âŒ flashcards_count = 10 â†’ ChÆ°a restart server

## ğŸ“ Táº I SAO Cáº¦N BIGRAMS?

Tiáº¿ng Anh cÃ³ nhiá»u khÃ¡i niá»‡m chá»‰ cÃ³ nghÄ©a khi káº¿t há»£p:

| Bigram | NghÄ©a | Unigrams | NghÄ©a |
|--------|-------|----------|-------|
| machine learning | Há»c mÃ¡y | machine + learning | MÃ¡y + Há»c |
| deep learning | Há»c sÃ¢u | deep + learning | SÃ¢u + Há»c |
| neural network | Máº¡ng nÆ¡-ron | neural + network | Tháº§n kinh + Máº¡ng |

â†’ Bigrams giá»¯ Ä‘Æ°á»£c **ngá»¯ cáº£nh** vÃ  **Ã½ nghÄ©a** Ä‘Ãºng!

## ğŸ”§ CÃC FIX ÄÃƒ ÃP Dá»¤NG

### 1. Ná»›i lá»ng bigram filter
**TrÆ°á»›c**: YÃªu cáº§u Cáº¢ 2 tá»« cÃ³ nghÄ©a
**Sau**: Chá»‰ cáº§n 1 trong 2 tá»« cÃ³ nghÄ©a

### 2. Giáº£m min_df
**TrÆ°á»›c**: `min_df=2` (loáº¡i bigrams hiáº¿m)
**Sau**: `min_df=1` (giá»¯ cáº£ bigrams hiáº¿m)

### 3. TÄƒng flashcards
**TrÆ°á»›c**: Hardcode 10
**Sau**: User chá»n (default 30)

### 4. TÄƒng max_words
**TrÆ°á»›c**: Default 20
**Sau**: Default 50

## âš ï¸ TROUBLESHOOTING

### Váº«n chá»‰ cÃ³ tá»« Ä‘Æ¡n?
1. ÄÃ£ restart server chÆ°a? â†’ `python main.py`
2. Kiá»ƒm tra `ensemble_extractor.py` dÃ²ng 390-395
3. Cháº¡y test: `python test_ngram_flashcard_fix.py`

### Váº«n chá»‰ 10 flashcards?
1. ÄÃ£ restart server chÆ°a?
2. CÃ³ truyá»n `max_flashcards=30` khÃ´ng?
3. Kiá»ƒm tra `main.py` dÃ²ng 597

### Server khÃ´ng cháº¡y?
```bash
# CÃ i dependencies
pip install -r requirements.txt

# Kiá»ƒm tra port
netstat -ano | findstr :8000

# Kill náº¿u cáº§n
taskkill /PID <PID> /F
```

## ğŸ“ Cáº¦N TRá»¢ GIÃšP?

Náº¿u váº«n gáº·p váº¥n Ä‘á»:

1. Cháº¡y test vÃ  gá»­i output:
   ```bash
   python test_ngram_flashcard_fix.py > test_output.txt
   ```

2. Kiá»ƒm tra server logs khi upload

3. Gá»­i response JSON tá»« upload endpoint

---

**TÃ³m táº¯t**: 
1. âœ… Restart server
2. âœ… Cháº¡y test
3. âœ… Kiá»ƒm tra cÃ³ bigrams + 30 flashcards

**Thá»i gian**: < 2 phÃºt

**Káº¿t quáº£**: Bigrams + nhiá»u flashcards hÆ¡n! ğŸ‰
