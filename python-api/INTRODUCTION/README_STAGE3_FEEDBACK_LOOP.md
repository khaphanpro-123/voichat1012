# STAGE 3 ‚Äì Learning Feedback Loop (Gi·∫£ Hu·∫•n Luy·ªán)

## üìñ T·ªïng quan

STAGE 3 l√† h·ªá th·ªëng **adaptive learning** cho ph√©p tr·ªçng s·ªë ensemble t·ª± ƒëi·ªÅu ch·ªânh d·ª±a tr√™n ph·∫£n h·ªìi ng∆∞·ªùi d√πng, **kh√¥ng c·∫ßn supervised training**.

## üéØ M·ª•c ti√™u

1. **Khai th√°c h√†nh vi** l·ª±a ch·ªçn t·ª´ v·ª±ng c·ªßa ng∆∞·ªùi h·ªçc
2. **ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë** c√°c th√†nh ph·∫ßn trong m√¥ h√¨nh ensemble
3. T·∫°o c∆° ch·∫ø **"gi·∫£ hu·∫•n luy·ªán"** (pseudo-training) kh√¥ng c·∫ßn d·ªØ li·ªáu g√°n nh√£n
4. **N√¢ng cao t√≠nh c√° nh√¢n h√≥a** v√† kh·∫£ nƒÉng th√≠ch ·ª©ng

## üîÑ Pipeline

```
User Feedback ‚Üí Feedback Memory ‚Üí Analysis ‚Üí Weight Adjustment ‚Üí Better Extraction
     ‚Üë                                                                    ‚Üì
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            Continuous Improvement Loop
```

## üìä C√°c b∆∞·ªõc chi ti·∫øt

### B∆Ø·ªöC 3.1 ‚Äì Thu th·∫≠p ph·∫£n h·ªìi ng∆∞·ªùi d√πng

**H√†nh vi ƒë∆∞·ª£c ghi nh·∫≠n:**
- ‚úÖ **Keep**: Gi·ªØ t·ª´ (t·ª´ h·ªØu √≠ch)
- ‚ùå **Drop**: Lo·∫°i b·ªè t·ª´ (t·ª´ kh√¥ng c·∫ßn thi·∫øt)
- ‚≠ê **Star**: ƒê√°nh d·∫•u quan tr·ªçng (t·ª´ r·∫•t quan tr·ªçng)

**D·ªØ li·ªáu l∆∞u tr·ªØ:**
```python
{
  "feedback_id": "fb_20260202_143052_123456",
  "word": "ontology",
  "document_id": "doc_01",
  "user_id": "user_01",
  "scores": {
    "tfidf": 0.85,
    "frequency": 0.45,
    "yake": 0.75,
    "rake": 0.65
  },
  "final_score": 0.82,
  "user_action": "keep",
  "timestamp": "2026-02-02T14:30:52",
  "weights_used": {
    "tfidf": 0.25,
    "frequency": 0.25,
    "yake": 0.25,
    "rake": 0.25
  }
}
```

**Code:**
```python
from feedback_loop import FeedbackCollector

collector = FeedbackCollector(storage_path="feedback_data")

feedback = collector.collect_feedback(
    word="ontology",
    document_id="doc_01",
    user_id="user_01",
    scores={'tfidf': 0.85, 'frequency': 0.45, 'yake': 0.75, 'rake': 0.65},
    final_score=0.82,
    user_action="keep",
    weights_used={'tfidf': 0.25, 'frequency': 0.25, 'yake': 0.25, 'rake': 0.25}
)
```

---

### B∆Ø·ªöC 3.2 ‚Äì T·ªï ch·ª©c kho ph·∫£n h·ªìi (Feedback Memory)

**M·ª•c ti√™u:** X√¢y d·ª±ng b·ªô nh·ªõ ph·∫£n h·ªìi ƒë·ªÉ ph·ª•c v·ª• ƒëi·ªÅu ch·ªânh m√¥ h√¨nh

**Features:**
- Load t·∫•t c·∫£ feedback
- Filter theo user_id
- Filter theo action (keep/drop/star)
- Th·ªëng k√™ feedback

**Code:**
```python
from feedback_loop import FeedbackMemory

memory = FeedbackMemory(storage_path="feedback_data")

# Load all feedback
all_feedback = memory.load_all_feedback()

# Get statistics
stats = memory.get_statistics()
# Output: {'total': 150, 'keep': 80, 'drop': 50, 'star': 20}

# Filter by user
user_feedback = memory.get_feedback_by_user("user_01")

# Filter by action
keep_feedback = memory.get_feedback_by_action("keep")
```

---

### B∆Ø·ªöC 3.3 ‚Äì Ph√¢n t√≠ch ph·∫£n h·ªìi (Core Logic)

**Nguy√™n t·∫Øc:**
- N·∫øu t·ª´ ƒë∆∞·ª£c **keep** v√† c√≥ **TF-IDF cao** ‚Üí TF-IDF c√≥ gi√° tr·ªã
- N·∫øu t·ª´ b·ªã **drop** nh∆∞ng **frequency cao** ‚Üí frequency g√¢y nhi·ªÖu

**Logic:**
```python
# Words kept with high TF-IDF
keep_words: tfidf=high, yake=high ‚Üí increase tfidf, yake weights

# Words dropped with high frequency
drop_words: frequency=high ‚Üí decrease frequency weight
```

**Code:**
```python
from feedback_loop import FeedbackAnalyzer

analyzer = FeedbackAnalyzer()

# Analyze feedback patterns
analysis = analyzer.analyze_feedback(all_feedback)

# Output:
# {
#   'keep': {'tfidf': 0.85, 'frequency': 0.40, 'yake': 0.78, 'rake': 0.65},
#   'drop': {'tfidf': 0.15, 'frequency': 0.92, 'yake': 0.20, 'rake': 0.18}
# }

# Identify positive methods
positive = analyzer.identify_positive_methods(analysis)
# Output: ['tfidf', 'yake', 'rake']

# Identify negative methods
negative = analyzer.identify_negative_methods(analysis)
# Output: ['frequency']
```

---

### B∆Ø·ªöC 3.4 ‚Äì ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë (Pseudo-Training)

**Tr·ªçng s·ªë ban ƒë·∫ßu:**
```python
{
  "tfidf": 0.25,
  "frequency": 0.25,
  "yake": 0.25,
  "rake": 0.25
}
```

**Lu·∫≠t c·∫≠p nh·∫≠t:**
```python
if user_action == "keep":
    # Increase weights of high-scoring methods
    for method in ['tfidf', 'frequency', 'yake', 'rake']:
        if scores[method] > threshold:
            weights[method] += learning_rate * scores[method]

if user_action == "drop":
    # Decrease weights of high-scoring methods
    for method in ['tfidf', 'frequency', 'yake', 'rake']:
        if scores[method] > threshold:
            weights[method] -= learning_rate * scores[method]

# Normalize weights to sum to 1.0
normalize(weights)
```

**V√≠ d·ª• sau ƒëi·ªÅu ch·ªânh:**
```python
{
  "tfidf": 0.32,      # ‚Üë Increased (good for keep)
  "frequency": 0.18,  # ‚Üì Decreased (causes drop)
  "yake": 0.28,       # ‚Üë Increased
  "rake": 0.22        # ‚Üí Stable
}
```

**Code:**
```python
from feedback_loop import WeightAdjuster

adjuster = WeightAdjuster(learning_rate=0.1)

# Get current weights
current = adjuster.get_current_weights()

# Adjust based on analysis
new_weights = adjuster.adjust_weights(analysis, feedback_count=150)

print(f"TF-IDF: {current.tfidf:.3f} ‚Üí {new_weights.tfidf:.3f}")
print(f"Frequency: {current.frequency:.3f} ‚Üí {new_weights.frequency:.3f}")
```

---

### B∆Ø·ªöC 3.5 ‚Äì √Åp d·ª•ng tr·ªçng s·ªë m·ªõi

**M·ª•c ti√™u:** T√†i li·ªáu x·ª≠ l√Ω sau s·∫Ω ƒë∆∞·ª£c tr√≠ch xu·∫•t t·ª´ v·ª±ng t·ªët h∆°n

**C√¥ng th·ª©c ensemble m·ªõi:**
```python
finalScore = w1 * tfidf + w2 * frequency + w3 * yake + w4 * rake
```
Trong ƒë√≥ `w1...w4` ƒë∆∞·ª£c c·∫≠p nh·∫≠t ƒë·ªông t·ª´ feedback.

**Code:**
```python
from ensemble_extractor import extract_vocabulary_ensemble
from feedback_loop import FeedbackLoop

loop = FeedbackLoop()

# Get adaptive weights
adaptive_weights = loop.get_current_weights()
# Output: {'tfidf': 0.32, 'frequency': 0.18, 'yake': 0.28, 'rake': 0.22}

# Extract with adaptive weights
result = extract_vocabulary_ensemble(
    text,
    max_words=50,
    weights=adaptive_weights  # ‚úÖ Use adaptive weights
)
```

---

### B∆Ø·ªöC 3.6 ‚Äì L∆∞u d·∫•u v·∫øt h·ªçc t·∫≠p (Traceability)

**M·ª•c ti√™u:** ƒê·∫£m b·∫£o t√≠nh gi·∫£i th√≠ch (explainability)

**M·ªói extraction l∆∞u:**
```python
{
  "word": "ontology",
  "finalScore": 0.84,
  "weightsUsed": {
    "tfidf": 0.32,
    "frequency": 0.18,
    "yake": 0.28,
    "rake": 0.22
  },
  "weightsVersion": 5,
  "feedbackCount": 150
}
```

**Explanation generation:**
```python
def generate_explanation(old_weights, new_weights, analysis):
    """
    T·∫°o explanation cho vi·ªác thay ƒë·ªïi tr·ªçng s·ªë
    
    Example output:
    "ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë: TF-IDF tƒÉng 0.25‚Üí0.32 (keep=0.85 > drop=0.15); 
     Frequency gi·∫£m 0.25‚Üí0.18 (drop=0.92 > keep=0.40)"
    """
```

---

## üîß API Endpoints

### 1. Submit Feedback
```http
POST /api/vocabulary-feedback
Content-Type: application/json

{
  "word": "ontology",
  "document_id": "doc_01",
  "user_id": "user_01",
  "scores": {
    "tfidf": 0.85,
    "frequency": 0.45,
    "yake": 0.75,
    "rake": 0.65
  },
  "final_score": 0.82,
  "user_action": "keep"
}
```

**Response:**
```json
{
  "success": true,
  "feedback_saved": true,
  "weights_updated": true,
  "new_weights": {
    "tfidf": 0.32,
    "frequency": 0.18,
    "yake": 0.28,
    "rake": 0.22
  },
  "explanation": "ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë: TF-IDF tƒÉng 0.25‚Üí0.32..."
}
```

### 2. Get Statistics
```http
GET /api/vocabulary-feedback/statistics?user_id=user_01
```

**Response:**
```json
{
  "success": true,
  "statistics": {
    "feedback_stats": {
      "total": 150,
      "keep": 80,
      "drop": 50,
      "star": 20
    },
    "current_weights": {
      "tfidf": 0.32,
      "frequency": 0.18,
      "yake": 0.28,
      "rake": 0.22
    },
    "weights_version": 5,
    "last_updated": "2026-02-02T14:30:52"
  }
}
```

### 3. Get Current Weights
```http
GET /api/vocabulary-feedback/weights
```

### 4. Extract with Adaptive Weights
```http
POST /api/smart-vocabulary-extract-adaptive
Content-Type: application/json

{
  "text": "Your document text...",
  "max_words": 50,
  "language": "en"
}
```

**Response includes adaptive weights info:**
```json
{
  "success": true,
  "vocabulary": [...],
  "adaptive_weights": {
    "weights": {"tfidf": 0.32, "frequency": 0.18, ...},
    "version": 5,
    "feedback_count": 150
  },
  "pipeline": "STAGE 1 (Adaptive) + STAGE 2 (Context) + STAGE 3 (Feedback)"
}
```

---

## üß™ Testing

```bash
# Run comprehensive tests
python test_feedback_loop.py
```

**Tests cover:**
- ‚úÖ Feedback collection
- ‚úÖ Feedback memory
- ‚úÖ Feedback analysis
- ‚úÖ Weight adjustment
- ‚úÖ Full feedback loop
- ‚úÖ Traceability

---

## üìä Example Scenario

### Initial State
```python
Weights: {tfidf: 0.25, frequency: 0.25, yake: 0.25, rake: 0.25}
```

### User Feedback (10 words)
```
Keep: ontology (tfidf=0.9), semantic (tfidf=0.85), knowledge (tfidf=0.82)
Drop: the (freq=0.98), and (freq=0.95), is (freq=0.92)
Star: AI (tfidf=0.95), ML (tfidf=0.93)
```

### After Analysis
```
Keep words: avg tfidf=0.88, avg frequency=0.40
Drop words: avg tfidf=0.12, avg frequency=0.95

‚Üí TF-IDF is positive (high in keep, low in drop)
‚Üí Frequency is negative (high in drop, low in keep)
```

### Weight Update
```python
New weights: {tfidf: 0.32, frequency: 0.18, yake: 0.28, rake: 0.22}

Explanation:
"TF-IDF tƒÉng 0.25‚Üí0.32 (keep=0.88 > drop=0.12)
 Frequency gi·∫£m 0.25‚Üí0.18 (drop=0.95 > keep=0.40)"
```

### Next Document
```
Uses new weights ‚Üí Better vocabulary extraction!
Academic words ranked higher, common words ranked lower.
```

---

## ‚úÖ CHECKLIST - STAGE 3

- [x] **H·ªá th·ªëng thu th·∫≠p ƒë∆∞·ª£c ph·∫£n h·ªìi ng∆∞·ªùi h·ªçc**
  - FeedbackCollector class
  - 3 actions: keep, drop, star
  - L∆∞u v√†o JSON files

- [x] **Ph·∫£n h·ªìi ƒë∆∞·ª£c l∆∞u d∆∞·ªõi d·∫°ng d·ªØ li·ªáu c√≥ c·∫•u tr√∫c**
  - VocabularyFeedback dataclass
  - C√≥ ƒë·∫ßy ƒë·ªß metadata (scores, weights_used, timestamp)

- [x] **Tr·ªçng s·ªë ensemble kh√¥ng c√≤n c·ªë ƒë·ªãnh**
  - EnsembleWeights class
  - T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh d·ª±a tr√™n feedback
  - L∆∞u version v√† history

- [x] **T√†i li·ªáu x·ª≠ l√Ω sau cho k·∫øt qu·∫£ t·ªët h∆°n t√†i li·ªáu tr∆∞·ªõc**
  - Adaptive weights ƒë∆∞·ª£c √°p d·ª•ng cho extraction ti·∫øp theo
  - Test cases ch·ª©ng minh improvement

- [x] **Gi·∫£i th√≠ch ƒë∆∞·ª£c v√¨ sao tr·ªçng s·ªë thay ƒë·ªïi**
  - generate_explanation() function
  - Breakdown analysis (keep vs drop scores)
  - Traceability ƒë·∫ßy ƒë·ªß

- [x] **Kh√¥ng s·ª≠ d·ª•ng m√¥ h√¨nh ML hu·∫•n luy·ªán s·∫µn**
  - 100% rule-based
  - Ch·ªâ d√πng statistics v√† heuristics
  - Kh√¥ng c√≥ neural networks, gradient descent, etc.

- [x] **C√≥ th·ªÉ m√¥ t·∫£ ƒë√¢y l√† adaptive learning system**
  - Continuous improvement loop
  - Self-adjusting based on user behavior
  - Pseudo-training without labeled data

**üéØ STAGE 3 ƒê·∫†T Y√äU C·∫¶U: 7/7**

---

## üöÄ Production Deployment

### Storage Options

**Option 1: File-based (Current)**
```python
FeedbackLoop(storage_path="feedback_data")
```
- Simple, no database needed
- Good for small-medium scale

**Option 2: Database (Recommended for production)**
```python
# MongoDB example
from pymongo import MongoClient

class FeedbackMemoryDB:
    def __init__(self, mongo_uri):
        self.client = MongoClient(mongo_uri)
        self.db = self.client.vocabulary_feedback
        self.collection = self.db.feedbacks
    
    def save_feedback(self, feedback):
        self.collection.insert_one(asdict(feedback))
    
    def load_all_feedback(self):
        return list(self.collection.find())
```

### Scaling Considerations

1. **Batch Updates**: Update weights every N feedbacks (default: 10)
2. **User-specific Weights**: Maintain separate weights per user
3. **A/B Testing**: Compare fixed vs adaptive weights
4. **Monitoring**: Track weight changes over time

---

## üìö References

- **Weak Supervision**: Using user behavior as weak labels
- **Online Learning**: Continuous model updates
- **Reinforcement Learning**: Reward (keep) vs Penalty (drop)
- **Adaptive Systems**: Self-adjusting based on feedback

---

## ü§ù Integration with STAGE 1 & 2

```python
# Complete pipeline
from ensemble_extractor import extract_vocabulary_ensemble
from context_intelligence import select_vocabulary_contexts
from feedback_loop import FeedbackLoop

# Initialize
loop = FeedbackLoop()

# STAGE 1: Extract with adaptive weights
adaptive_weights = loop.get_current_weights()
vocab_result = extract_vocabulary_ensemble(text, weights=adaptive_weights)

# STAGE 2: Select contexts
contexts = select_vocabulary_contexts(text, vocab_result['scores'])

# User reviews and provides feedback
for ctx in contexts:
    user_action = get_user_feedback(ctx)  # keep/drop/star
    
    # STAGE 3: Process feedback
    loop.process_feedback(
        word=ctx['word'],
        scores=ctx['features'],
        user_action=user_action,
        ...
    )

# Next document will use improved weights!
```

---

**Ng√†y t·∫°o:** 2026-02-02  
**Version:** 1.0.0  
**Status:** ‚úÖ Production Ready
