# ğŸ“ Visual Language Tutor - Python API

## ğŸš€ KHá»I Äá»˜NG NHANH

### 1. CÃ i Ä‘áº·t

```bash
cd python-api
pip install -r requirements.txt
python download_nltk_data.py
python -m spacy download en_core_web_sm
```

### 2. Cháº¡y Server

```bash
python main.py
```

Server cháº¡y táº¡i: **http://127.0.0.1:8000**

### 3. Má»Ÿ Swagger UI

Truy cáº­p: **http://127.0.0.1:8000/docs**

### 4. Upload TÃ i Liá»‡u

1. TÃ¬m endpoint **POST /api/upload-document**
2. Click **"Try it out"**
3. Chá»n file (.txt, .pdf, .docx)
4. Click **"Execute"**
5. Xem káº¿t quáº£!

## âœ… TÃNH NÄ‚NG

### ğŸ“¤ Upload & Extract
- Upload file (.txt, .pdf, .docx)
- TrÃ­ch xuáº¥t tá»« vá»±ng tá»± Ä‘á»™ng
- Táº¡o flashcards
- Giáº£i thÃ­ch tá»« vá»±ng

### ğŸ§  AI Pipeline (STAGE 1-5)
1. **Ensemble Extraction**: TF-IDF + RAKE + YAKE + Frequency
2. **Context Intelligence**: Chá»n cÃ¢u ngá»¯ cáº£nh tá»‘t nháº¥t
3. **Feedback Loop**: Adaptive weights tá»« user feedback
4. **Knowledge Graph**: XÃ¢y dá»±ng Ä‘á»“ thá»‹ tri thá»©c
5. **RAG System**: Táº¡o flashcards vá»›i AI

## ğŸ“š API ENDPOINTS

### Upload Document
```bash
POST /api/upload-document
```
Upload file vÃ  trÃ­ch xuáº¥t tá»« vá»±ng

### Smart Extract
```bash
POST /api/smart-vocabulary-extract
```
TrÃ­ch xuáº¥t tá»« text (khÃ´ng cáº§n upload)

### Generate Flashcards
```bash
POST /api/rag/generate-flashcards
```
Táº¡o flashcards tá»« document

### Explain Term
```bash
POST /api/rag/explain-term
```
Giáº£i thÃ­ch tá»« vá»±ng vá»›i AI

### Find Related
```bash
POST /api/rag/find-related
```
TÃ¬m tá»« liÃªn quan

## ğŸ§ª TESTING

```bash
# Test upload
python test_upload.py

# Test ensemble extractor
python test_ensemble_direct.py

# Test server
python test_server.py
```

## ğŸ“– TÃ€I LIá»†U

- **QUICK_START_UPLOAD.md**: HÆ°á»›ng dáº«n upload chi tiáº¿t
- **UPLOAD_GUIDE.md**: HÆ°á»›ng dáº«n Ä‘áº§y Ä‘á»§
- **README_STAGE*.md**: TÃ i liá»‡u tá»«ng stage

## ğŸ¯ VÃ Dá»¤

### Python
```python
import requests

# Upload file
with open("document.txt", "rb") as f:
    files = {"file": ("document.txt", f)}
    data = {"max_words": 20, "language": "en"}
    
    response = requests.post(
        "http://127.0.0.1:8000/api/upload-document",
        files=files,
        data=data
    )
    
    result = response.json()
    print(f"âœ… Extracted {result['vocabulary_count']} words!")
```

### curl
```bash
curl -X POST "http://127.0.0.1:8000/api/upload-document" \
  -F "file=@document.txt" \
  -F "max_words=20" \
  -F "language=en"
```

## ğŸ› TROUBLESHOOTING

### Lá»—i: "punkt_tab not found"
```bash
python download_nltk_data.py
```

### Lá»—i: "en_core_web_sm not found"
```bash
python -m spacy download en_core_web_sm
```

### Lá»—i: "PDF/DOCX support not available"
```bash
pip install PyPDF2 python-docx
```

## ğŸ“ Cáº¤U TRÃšC

```
python-api/
â”œâ”€â”€ main.py                      # FastAPI server
â”œâ”€â”€ ensemble_extractor.py        # STAGE 1: Ensemble extraction
â”œâ”€â”€ context_intelligence.py      # STAGE 2: Context selection
â”œâ”€â”€ feedback_loop.py             # STAGE 3: Adaptive learning
â”œâ”€â”€ knowledge_graph.py           # STAGE 4: Knowledge graph
â”œâ”€â”€ rag_system.py                # STAGE 5: RAG system
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ test_upload.py               # Upload test
â”œâ”€â”€ test_ensemble_direct.py      # Ensemble test
â”œâ”€â”€ download_nltk_data.py        # NLTK data downloader
â”œâ”€â”€ uploads/                     # Uploaded files
â”œâ”€â”€ feedback_data/               # Feedback storage
â””â”€â”€ knowledge_graph_data/        # Knowledge graph storage
```

## ğŸ‰ HOÃ€N THÃ€NH!

Há»‡ thá»‘ng Ä‘Ã£ sáºµn sÃ ng sá»­ dá»¥ng! Báº¡n cÃ³ thá»ƒ:
- âœ… Upload tÃ i liá»‡u
- âœ… TrÃ­ch xuáº¥t tá»« vá»±ng tá»± Ä‘á»™ng
- âœ… Táº¡o flashcards
- âœ… Giáº£i thÃ­ch tá»« vá»±ng
- âœ… Sá»­ dá»¥ng toÃ n bá»™ AI pipeline

---

**Made with â¤ï¸ for language learners**
