# üö® C√ÅC L·ªñI NGHI√äM TR·ªåNG C·∫¶N S·ª¨A NGAY

## üìã PH√ÇN T√çCH K·∫æT QU·∫¢ HI·ªÜN T·∫†I

### ‚ùå L·ªói 1: Vocabulary to√†n t·ª´ ƒë∆°n v√¥ nghƒ©a

**Hi·ªán t·∫°i**:
```json
{
  "vocabulary": [
    {"word": "lot", "score": 0.76},
    {"word": "lof", "score": 0.58},  // L·ªói ch√≠nh t·∫£
    {"word": "take", "score": 0.54},
    {"word": "yeu", "score": 0.51},  // Ti·∫øng Vi·ªát
    {"word": "nhan", "score": 0.51}  // Ti·∫øng Vi·ªát
  ]
}
```

**V·∫•n ƒë·ªÅ**:
- To√†n t·ª´ ƒë∆°n kh√¥ng c√≥ nghƒ©a
- C√≥ l·ªói ch√≠nh t·∫£ ("lof")
- L·∫´n ti·∫øng Vi·ªát ("yeu", "nhan")
- Kh√¥ng c√≥ phrases ("soft skills", "job opportunities")

**Mong ƒë·ª£i**:
```json
{
  "vocabulary": [
    {"phrase": "soft skills", "score": 0.85, "cluster": "personal_development"},
    {"phrase": "job opportunities", "score": 0.82, "cluster": "career"},
    {"phrase": "volunteer work", "score": 0.78, "cluster": "social_contribution"},
    {"phrase": "healthy lifestyle", "score": 0.75, "cluster": "health"}
  ]
}
```

---

### ‚ùå L·ªói 2: TF-IDF = 0 (kh√¥ng ho·∫°t ƒë·ªông)

**Hi·ªán t·∫°i**:
```json
{
  "features": {
    "frequency": 0.032,
    "tfidf": 0,        // ‚ùå TF-IDF = 0!
    "rake": 3.72,
    "yake": 20.26
  }
}
```

**Nguy√™n nh√¢n**:
```python
# ensemble_extractor.py - Line ~143
def calculate_tfidf(documents: List[str]) -> Dict[str, float]:
    vectorizer = TfidfVectorizer(...)
    tfidf_matrix = vectorizer.fit_transform(documents)
    
    # ‚ùå V·∫§N ƒê·ªÄ: documents ch·ªâ c√≥ 1 ph·∫ßn t·ª≠!
    # documents = [full_text]  # Ch·ªâ 1 document
    # ‚Üí IDF = log(1/1) = 0
    # ‚Üí TF-IDF = TF * 0 = 0
```

**Gi·∫£i ph√°p**:
```python
# ‚úÖ PH·∫¢I L√ÄM: Chia th√†nh nhi·ªÅu documents
documents = split_into_sentences(text)  # Nhi·ªÅu sentences
# documents = [sent1, sent2, sent3, ...]
# ‚Üí IDF c√≥ nghƒ©a
# ‚Üí TF-IDF ho·∫°t ƒë·ªông ƒë√∫ng
```

---

### ‚ùå L·ªói 3: K-means cluster WORDS (sai ƒë·ªëi t∆∞·ª£ng)

**Hi·ªán t·∫°i**:
```json
{
  "kmeans_clustering": {
    "clusters": [
      {
        "cluster_id": 0,
        "words": ["take", "part", "interesting"],  // ‚ùå Cluster words
        "label": "Products & Good & Buy"
      }
    ]
  }
}
```

**V·∫•n ƒë·ªÅ**:
- Cluster words thay v√¨ sentences
- Words kh√¥ng c√≥ ng·ªØ c·∫£nh
- Label kh√¥ng ch√≠nh x√°c

**Mong ƒë·ª£i**:
```json
{
  "kmeans_clustering": {
    "clusters": [
      {
        "cluster_id": 0,
        "theme": "Personal Development",
        "sentences": [
          "Studying abroad helps students improve soft skills.",
          "Teamwork and communication skills are essential."
        ],
        "representative_phrases": [
          "soft skills",
          "teamwork",
          "communication skills"
        ]
      }
    ]
  }
}
```

---

### ‚ùå L·ªói 4: Flashcards fallback (LLM kh√¥ng ho·∫°t ƒë·ªông)

**Hi·ªán t·∫°i**:
```json
{
  "flashcards": [
    {
      "term": "lot",
      "meaning": "Academic term from DE Agree or disagree.docx",
      "example": "therefore, there are a lot of AAA...",
      "generation_method": "fallback"  // ‚ùå LLM failed
    }
  ]
}
```

**V·∫•n ƒë·ªÅ**:
- LLM kh√¥ng sinh ƒë∆∞·ª£c definition
- Fallback generic kh√¥ng c√≥ gi√° tr·ªã
- Term l√† t·ª´ ƒë∆°n v√¥ nghƒ©a

**Mong ƒë·ª£i**:
```json
{
  "flashcards": [
    {
      "term": "soft skills",
      "meaning": "Personal attributes that enable effective interaction and work with others",
      "example": "Studying abroad helps students improve soft skills like teamwork and communication.",
      "cluster": "personal_development",
      "generation_method": "llm_controlled"
    }
  ]
}
```

---

## üîß K·∫æ HO·∫†CH S·ª¨A (THEO TH·ª® T·ª∞ ∆ØU TI√äN)

### üî¥ FIX 1: TF-IDF tr√™n sentences (QUAN TR·ªåNG NH·∫§T)

**File**: `ensemble_extractor.py`

**V·∫•n ƒë·ªÅ hi·ªán t·∫°i**:
```python
def extract_vocabulary_ensemble(text: str, ...):
    # ‚ùå TF-IDF tr√™n to√†n b·ªô text (1 document)
    tfidf_scores = calculate_tfidf([text])  # Ch·ªâ 1 document!
```

**S·ª≠a th√†nh**:
```python
def extract_vocabulary_ensemble_v2(text: str, ...):
    # ‚úÖ B∆Ø·ªöC 1: Split th√†nh sentences
    sentences = sent_tokenize(text)
    
    # ‚úÖ B∆Ø·ªöC 2: TF-IDF tr√™n sentences
    tfidf_scores = calculate_tfidf_on_sentences(sentences)
    
    # ‚úÖ B∆Ø·ªöC 3: Extract phrases (kh√¥ng ph·∫£i words)
    phrases = extract_phrases_from_tfidf(tfidf_scores)
    
    return phrases
```

**Code chi ti·∫øt**:
```python
def calculate_tfidf_on_sentences(sentences: List[str]) -> Dict[str, float]:
    """
    TF-IDF tr√™n nhi·ªÅu sentences v·ªõi n-gram (2-3)
    """
    vectorizer = TfidfVectorizer(
        max_features=1000,
        ngram_range=(2, 3),      # ‚úÖ Bigram + Trigram
        min_df=2,                # ‚úÖ Xu·∫•t hi·ªán √≠t nh·∫•t 2 sentences
        max_df=0.8,
        stop_words='english',
        norm='l2'
    )
    
    # ‚úÖ Fit tr√™n NHI·ªÄU sentences
    tfidf_matrix = vectorizer.fit_transform(sentences)
    feature_names = vectorizer.get_feature_names_out()
    
    # Aggregate scores
    mean_scores = tfidf_matrix.mean(axis=0).A1
    
    tfidf_scores = {}
    for idx, score in enumerate(mean_scores):
        if score > 0:
            phrase = feature_names[idx]
            # ‚úÖ Ch·ªâ gi·ªØ phrases (c√≥ d·∫•u c√°ch)
            if ' ' in phrase:
                tfidf_scores[phrase] = score
    
    return tfidf_scores
```

---

### üî¥ FIX 2: K-means cluster SENTENCES

**File m·ªõi**: `sentence_clustering_v2.py`

```python
"""
Sentence Clustering - Cluster sentences th√†nh themes
"""

from typing import List, Dict
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from nltk.tokenize import sent_tokenize

def cluster_sentences_by_theme(
    text: str,
    n_clusters: int = 4
) -> Dict:
    """
    Cluster sentences th√†nh c√°c themes
    
    Returns:
        {
            'clusters': [
                {
                    'theme': 'Personal Development',
                    'sentences': [...],
                    'phrases': ['soft skills', 'teamwork']
                }
            ]
        }
    """
    # B∆Ø·ªöC 1: Split sentences
    sentences = sent_tokenize(text)
    
    if len(sentences) < n_clusters * 2:
        return {'error': 'Not enough sentences'}
    
    # B∆Ø·ªöC 2: TF-IDF vectorization
    vectorizer = TfidfVectorizer(
        max_features=500,
        ngram_range=(1, 2),
        stop_words='english'
    )
    
    tfidf_matrix = vectorizer.fit_transform(sentences)
    
    # B∆Ø·ªöC 3: K-means clustering
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    cluster_labels = kmeans.fit_predict(tfidf_matrix)
    
    # B∆Ø·ªöC 4: Group sentences by cluster
    clusters = {}
    for idx, label in enumerate(cluster_labels):
        if label not in clusters:
            clusters[label] = []
        clusters[label].append(sentences[idx])
    
    # B∆Ø·ªöC 5: Extract phrases per cluster
    results = []
    for cluster_id, cluster_sentences in clusters.items():
        # TF-IDF tr√™n cluster n√†y
        cluster_tfidf = TfidfVectorizer(
            ngram_range=(2, 3),
            max_features=10,
            stop_words='english'
        )
        
        cluster_matrix = cluster_tfidf.fit_transform(cluster_sentences)
        phrases = cluster_tfidf.get_feature_names_out()
        
        # Get scores
        scores = cluster_matrix.mean(axis=0).A1
        top_phrases = [
            {'phrase': phrases[i], 'score': float(scores[i])}
            for i in scores.argsort()[-5:][::-1]
        ]
        
        results.append({
            'cluster_id': cluster_id,
            'theme': generate_theme_name(top_phrases),
            'sentences': cluster_sentences,
            'representative_phrases': top_phrases
        })
    
    return {'clusters': results}


def generate_theme_name(phrases: List[Dict]) -> str:
    """
    Generate theme name t·ª´ top phrases
    """
    if not phrases:
        return "General"
    
    # Simple: L·∫•y phrase ƒë·∫ßu ti√™n
    top_phrase = phrases[0]['phrase']
    
    # Capitalize
    return top_phrase.title().replace(' ', '_')
```

---

### üî¥ FIX 3: L·ªçc t·ª´ v·ª±ng ti·∫øng Vi·ªát v√† l·ªói ch√≠nh t·∫£

**File**: `ensemble_extractor.py`

**Th√™m filter**:
```python
def is_valid_english_phrase(phrase: str) -> bool:
    """
    Ki·ªÉm tra phrase c√≥ ph·∫£i ti·∫øng Anh h·ª£p l·ªá kh√¥ng
    """
    # Check 1: Ch·ªâ ch·ª©a k√Ω t·ª± ASCII
    if not all(ord(c) < 128 or c.isspace() for c in phrase):
        return False
    
    # Check 2: Kh√¥ng ph·∫£i stopwords ƒë∆°n
    words = phrase.split()
    if len(words) == 1 and words[0] in ENGLISH_STOPWORDS:
        return False
    
    # Check 3: Spell check (optional)
    # C√≥ th·ªÉ d√πng pyspellchecker
    
    return True


def filter_vietnamese_and_errors(phrases: List[str]) -> List[str]:
    """
    L·ªçc b·ªè ti·∫øng Vi·ªát v√† l·ªói ch√≠nh t·∫£
    """
    filtered = []
    
    for phrase in phrases:
        # Lo·∫°i ti·∫øng Vi·ªát
        vietnamese_words = ['yeu', 'nhan', 'lof', 'thcih']
        if any(vn in phrase.lower() for vn in vietnamese_words):
            continue
        
        # Ki·ªÉm tra valid
        if is_valid_english_phrase(phrase):
            filtered.append(phrase)
    
    return filtered
```

---

### üî¥ FIX 4: LLM c√≥ ki·ªÉm so√°t t·ª´ v·ª±ng

**File**: `rag_system.py`

**S·ª≠a generate_flashcards**:
```python
def generate_flashcards_controlled(
    self,
    cluster_phrases: List[Dict],
    max_cards: int = 30
) -> List[Dict]:
    """
    Generate flashcards v·ªõi t·ª´ v·ª±ng ƒë∆∞·ª£c ki·ªÉm so√°t
    
    Args:
        cluster_phrases: [
            {
                'phrase': 'soft skills',
                'cluster': 'personal_development',
                'context': 'Studying abroad helps...'
            }
        ]
    """
    flashcards = []
    
    # T·∫°o vocabulary list
    all_phrases = [p['phrase'] for p in cluster_phrases]
    
    for phrase_data in cluster_phrases[:max_cards]:
        phrase = phrase_data['phrase']
        context = phrase_data.get('context', '')
        
        # LLM prompt v·ªõi STRICT control
        prompt = f"""
Generate a flashcard for the term: "{phrase}"

STRICT RULES:
1. You MUST define "{phrase}" accurately
2. Use ONLY vocabulary from this list: {', '.join(all_phrases)}
3. DO NOT invent new terms
4. Keep definition concise (1-2 sentences)

Context: {context}

Output format:
Definition: [your definition]
Example: [example sentence using the term]
"""
        
        try:
            response = self.llm_client.chat.completions.create(
                model=self.llm_model,
                messages=[
                    {"role": "system", "content": "You are a vocabulary teacher. Follow instructions strictly."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,  # Low temperature for consistency
                max_tokens=150
            )
            
            content = response.choices[0].message.content
            
            # Parse response
            definition, example = self._parse_llm_response(content)
            
            flashcard = {
                'term': phrase,
                'meaning': definition,
                'example': example,
                'cluster': phrase_data.get('cluster', 'general'),
                'generation_method': 'llm_controlled'
            }
            
        except Exception as e:
            # Fallback: Template-based
            flashcard = {
                'term': phrase,
                'meaning': f"A key concept related to {phrase_data.get('cluster', 'general')}",
                'example': context,
                'cluster': phrase_data.get('cluster', 'general'),
                'generation_method': 'template'
            }
        
        flashcards.append(flashcard)
    
    return flashcards


def _parse_llm_response(self, content: str) -> Tuple[str, str]:
    """
    Parse LLM response th√†nh definition v√† example
    """
    lines = content.strip().split('\n')
    
    definition = ""
    example = ""
    
    for line in lines:
        if line.startswith('Definition:'):
            definition = line.replace('Definition:', '').strip()
        elif line.startswith('Example:'):
            example = line.replace('Example:', '').strip()
    
    return definition, example
```

---

## üìä K·∫æT QU·∫¢ MONG ƒê·ª¢I SAU KHI S·ª¨A

### ‚úÖ Vocabulary (phrases c√≥ nghƒ©a)
```json
{
  "vocabulary": [
    {
      "phrase": "soft skills",
      "score": 0.85,
      "cluster": "personal_development",
      "tfidf": 0.42,  // ‚úÖ TF-IDF ho·∫°t ƒë·ªông
      "context": "Studying abroad helps students improve soft skills."
    },
    {
      "phrase": "job opportunities",
      "score": 0.82,
      "cluster": "career",
      "tfidf": 0.38,
      "context": "They will have many job opportunities in big companies."
    }
  ]
}
```

### ‚úÖ K-means (cluster sentences)
```json
{
  "kmeans_clustering": {
    "clusters": [
      {
        "cluster_id": 0,
        "theme": "Personal_Development",
        "sentences": [
          "Studying abroad helps students improve soft skills.",
          "Teamwork and communication skills are essential."
        ],
        "representative_phrases": [
          {"phrase": "soft skills", "score": 0.85},
          {"phrase": "communication skills", "score": 0.78}
        ]
      }
    ]
  }
}
```

### ‚úÖ Flashcards (LLM controlled)
```json
{
  "flashcards": [
    {
      "term": "soft skills",
      "meaning": "Personal attributes that enable effective interaction and work with others, including communication, teamwork, and problem-solving abilities.",
      "example": "Studying abroad helps students improve soft skills like teamwork and communication.",
      "cluster": "personal_development",
      "generation_method": "llm_controlled"
    }
  ]
}
```

---

## ‚úÖ CHECKLIST S·ª¨A

- [ ] Fix 1: TF-IDF tr√™n sentences (kh√¥ng ph·∫£i 1 document)
- [ ] Fix 2: K-means cluster sentences (kh√¥ng ph·∫£i words)
- [ ] Fix 3: Extract phrases per cluster
- [ ] Fix 4: L·ªçc ti·∫øng Vi·ªát v√† l·ªói ch√≠nh t·∫£
- [ ] Fix 5: LLM c√≥ ki·ªÉm so√°t t·ª´ v·ª±ng
- [ ] Fix 6: Flashcards t·ª´ cluster phrases

---

## üöÄ B∆Ø·ªöC TI·∫æP THEO

B·∫°n mu·ªën t√¥i:

**Option 1**: Implement t·ª´ng fix (vi·∫øt code ƒë·∫ßy ƒë·ªß)
**Option 2**: T·∫°o file m·ªõi ho√†n ch·ªânh thay th·∫ø file c≈©
**Option 3**: Ch·ªâ vi·∫øt documentation cho thesis

B·∫°n ch·ªçn option n√†o? üéØ
