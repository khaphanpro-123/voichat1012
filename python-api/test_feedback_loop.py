"""
Test script for STAGE 3 - Learning Feedback Loop
"""

import os
import shutil
from feedback_loop import (
    FeedbackLoop,
    FeedbackCollector,
    FeedbackMemory,
    FeedbackAnalyzer,
    WeightAdjuster
)

# Test data directory
TEST_DIR = "test_feedback_data"

def cleanup_test_data():
    """Clean up test data"""
    if os.path.exists(TEST_DIR):
        shutil.rmtree(TEST_DIR)
    if os.path.exists("ensemble_weights.json"):
        os.remove("ensemble_weights.json")

def test_feedback_collector():
    """Test BÆ¯á»šC 3.1: Thu tháº­p pháº£n há»“i"""
    print("\n" + "=" * 80)
    print("TEST BÆ¯á»šC 3.1 - Thu tháº­p pháº£n há»“i ngÆ°á»i dÃ¹ng")
    print("=" * 80)
    
    collector = FeedbackCollector(TEST_DIR)
    
    # Collect feedback
    feedback = collector.collect_feedback(
        word="ontology",
        document_id="doc_01",
        user_id="user_01",
        scores={'tfidf': 0.85, 'frequency': 0.45, 'yake': 0.75, 'rake': 0.65},
        final_score=0.82,
        user_action="keep",
        weights_used={'tfidf': 0.25, 'frequency': 0.25, 'yake': 0.25, 'rake': 0.25}
    )
    
    print(f"âœ… Feedback collected: {feedback.word} â†’ {feedback.user_action}")
    print(f"   Feedback ID: {feedback.feedback_id}")
    print(f"   Scores: {feedback.scores}")
    
    # Verify file saved
    files = os.listdir(TEST_DIR)
    assert len(files) == 1, "Feedback file should be saved"
    print(f"âœ… Feedback saved to file: {files[0]}")


def test_feedback_memory():
    """Test BÆ¯á»šC 3.2: Tá»• chá»©c kho pháº£n há»“i"""
    print("\n" + "=" * 80)
    print("TEST BÆ¯á»šC 3.2 - Tá»• chá»©c kho pháº£n há»“i")
    print("=" * 80)
    
    collector = FeedbackCollector(TEST_DIR)
    memory = FeedbackMemory(TEST_DIR)
    
    # Add multiple feedbacks
    test_data = [
        ('word1', 'keep', {'tfidf': 0.9, 'frequency': 0.3, 'yake': 0.8, 'rake': 0.7}),
        ('word2', 'keep', {'tfidf': 0.85, 'frequency': 0.4, 'yake': 0.75, 'rake': 0.65}),
        ('word3', 'drop', {'tfidf': 0.2, 'frequency': 0.9, 'yake': 0.3, 'rake': 0.25}),
        ('word4', 'drop', {'tfidf': 0.15, 'frequency': 0.95, 'yake': 0.2, 'rake': 0.2}),
        ('word5', 'star', {'tfidf': 0.95, 'frequency': 0.5, 'yake': 0.9, 'rake': 0.85}),
    ]
    
    for word, action, scores in test_data:
        collector.collect_feedback(
            word=word,
            document_id="doc_test",
            user_id="user_test",
            scores=scores,
            final_score=0.7,
            user_action=action,
            weights_used={'tfidf': 0.25, 'frequency': 0.25, 'yake': 0.25, 'rake': 0.25}
        )
    
    # Load all feedback
    all_feedback = memory.load_all_feedback()
    print(f"âœ… Total feedbacks: {len(all_feedback)}")
    
    # Get statistics
    stats = memory.get_statistics()
    print(f"âœ… Statistics: {stats}")
    
    assert stats['total'] == 6, "Should have 6 feedbacks (1 from previous test + 5 new)"
    assert stats['keep'] == 3, "Should have 3 keep actions"
    assert stats['drop'] == 2, "Should have 2 drop actions"
    assert stats['star'] == 1, "Should have 1 star action"


def test_feedback_analyzer():
    """Test BÆ¯á»šC 3.3: PhÃ¢n tÃ­ch pháº£n há»“i"""
    print("\n" + "=" * 80)
    print("TEST BÆ¯á»šC 3.3 - PhÃ¢n tÃ­ch pháº£n há»“i")
    print("=" * 80)
    
    memory = FeedbackMemory(TEST_DIR)
    analyzer = FeedbackAnalyzer()
    
    # Load feedback
    all_feedback = memory.load_all_feedback()
    
    # Analyze
    analysis = analyzer.analyze_feedback(all_feedback)
    
    print(f"âœ… Keep scores: {analysis['keep']}")
    print(f"âœ… Drop scores: {analysis['drop']}")
    
    # Identify positive/negative methods
    positive = analyzer.identify_positive_methods(analysis)
    negative = analyzer.identify_negative_methods(analysis)
    
    print(f"âœ… Positive methods (good for keep): {positive}")
    print(f"âœ… Negative methods (cause noise): {negative}")
    
    # Verify logic
    assert 'tfidf' in positive, "TF-IDF should be positive (high in keep, low in drop)"
    assert 'frequency' in negative, "Frequency should be negative (high in drop, low in keep)"


def test_weight_adjuster():
    """Test BÆ¯á»šC 3.4: Äiá»u chá»‰nh trá»ng sá»‘"""
    print("\n" + "=" * 80)
    print("TEST BÆ¯á»šC 3.4 - Äiá»u chá»‰nh trá»ng sá»‘")
    print("=" * 80)
    
    memory = FeedbackMemory(TEST_DIR)
    analyzer = FeedbackAnalyzer()
    adjuster = WeightAdjuster(learning_rate=0.1, weights_file="test_weights.json")
    
    # Get initial weights
    initial_weights = adjuster.get_current_weights()
    print(f"Initial weights:")
    print(f"  TF-IDF: {initial_weights.tfidf:.3f}")
    print(f"  Frequency: {initial_weights.frequency:.3f}")
    print(f"  YAKE: {initial_weights.yake:.3f}")
    print(f"  RAKE: {initial_weights.rake:.3f}")
    
    # Analyze feedback
    all_feedback = memory.load_all_feedback()
    analysis = analyzer.analyze_feedback(all_feedback)
    
    # Adjust weights
    new_weights = adjuster.adjust_weights(analysis, len(all_feedback))
    
    print(f"\nâœ… New weights:")
    print(f"  TF-IDF: {new_weights.tfidf:.3f}")
    print(f"  Frequency: {new_weights.frequency:.3f}")
    print(f"  YAKE: {new_weights.yake:.3f}")
    print(f"  RAKE: {new_weights.rake:.3f}")
    
    # Verify changes
    assert new_weights.tfidf > initial_weights.tfidf, "TF-IDF should increase (positive method)"
    assert new_weights.frequency < initial_weights.frequency, "Frequency should decrease (negative method)"
    
    # Verify normalization
    total = new_weights.tfidf + new_weights.frequency + new_weights.yake + new_weights.rake
    assert abs(total - 1.0) < 0.001, "Weights should sum to 1.0"
    
    print(f"âœ… Weights normalized: sum = {total:.3f}")
    
    # Clean up
    if os.path.exists("test_weights.json"):
        os.remove("test_weights.json")


def test_full_feedback_loop():
    """Test BÆ¯á»šC 3.5 & 3.6: Full feedback loop"""
    print("\n" + "=" * 80)
    print("TEST BÆ¯á»šC 3.5 & 3.6 - Full Feedback Loop")
    print("=" * 80)
    
    # Clean up and start fresh
    cleanup_test_data()
    
    loop = FeedbackLoop(storage_path=TEST_DIR, learning_rate=0.15)
    
    # Simulate realistic feedback scenario
    scenarios = [
        # Scenario 1: Academic words (high TF-IDF, YAKE) â†’ keep
        {
            'word': 'ontology',
            'scores': {'tfidf': 0.92, 'frequency': 0.35, 'yake': 0.88, 'rake': 0.75},
            'final_score': 0.85,
            'action': 'keep'
        },
        {
            'word': 'semantic',
            'scores': {'tfidf': 0.88, 'frequency': 0.40, 'yake': 0.82, 'rake': 0.70},
            'final_score': 0.82,
            'action': 'keep'
        },
        {
            'word': 'knowledge',
            'scores': {'tfidf': 0.85, 'frequency': 0.45, 'yake': 0.80, 'rake': 0.68},
            'final_score': 0.80,
            'action': 'keep'
        },
        
        # Scenario 2: Common words (high frequency, low TF-IDF) â†’ drop
        {
            'word': 'the',
            'scores': {'tfidf': 0.05, 'frequency': 0.98, 'yake': 0.10, 'rake': 0.08},
            'final_score': 0.42,
            'action': 'drop'
        },
        {
            'word': 'and',
            'scores': {'tfidf': 0.03, 'frequency': 0.95, 'yake': 0.08, 'rake': 0.06},
            'final_score': 0.40,
            'action': 'drop'
        },
        {
            'word': 'is',
            'scores': {'tfidf': 0.08, 'frequency': 0.92, 'yake': 0.12, 'rake': 0.10},
            'final_score': 0.43,
            'action': 'drop'
        },
        
        # Scenario 3: Important words â†’ star
        {
            'word': 'artificial intelligence',
            'scores': {'tfidf': 0.95, 'frequency': 0.50, 'yake': 0.92, 'rake': 0.88},
            'final_score': 0.90,
            'action': 'star'
        },
        {
            'word': 'machine learning',
            'scores': {'tfidf': 0.93, 'frequency': 0.48, 'yake': 0.90, 'rake': 0.85},
            'final_score': 0.88,
            'action': 'star'
        },
        
        # More keep examples
        {
            'word': 'algorithm',
            'scores': {'tfidf': 0.87, 'frequency': 0.42, 'yake': 0.83, 'rake': 0.72},
            'final_score': 0.81,
            'action': 'keep'
        },
        {
            'word': 'neural network',
            'scores': {'tfidf': 0.90, 'frequency': 0.38, 'yake': 0.86, 'rake': 0.78},
            'final_score': 0.84,
            'action': 'keep'
        },
    ]
    
    print(f"\nðŸ“Š Processing {len(scenarios)} feedback scenarios...")
    
    for i, scenario in enumerate(scenarios, 1):
        result = loop.process_feedback(
            word=scenario['word'],
            document_id='doc_test',
            user_id='user_test',
            scores=scenario['scores'],
            final_score=scenario['final_score'],
            user_action=scenario['action']
        )
        
        print(f"\n--- Feedback {i}/10 ---")
        print(f"Word: '{scenario['word']}' â†’ {scenario['action']}")
        
        if result['weights_updated']:
            print(f"âœ… Weights updated!")
            print(f"   {result['explanation']}")
            print(f"   New weights: {result['new_weights']}")
    
    # Get final statistics
    print("\n" + "=" * 80)
    print("ðŸ“ˆ FINAL RESULTS")
    print("=" * 80)
    
    stats = loop.get_statistics()
    
    print(f"\nðŸ“Š Feedback Statistics:")
    print(f"   Total: {stats['feedback_stats']['total']}")
    print(f"   Keep: {stats['feedback_stats']['keep']}")
    print(f"   Drop: {stats['feedback_stats']['drop']}")
    print(f"   Star: {stats['feedback_stats']['star']}")
    
    print(f"\nâš–ï¸  Final Weights (Version {stats['weights_version']}):")
    for method, weight in stats['current_weights'].items():
        print(f"   {method.upper()}: {weight:.3f}")
    
    # Verify expected behavior
    weights = stats['current_weights']
    assert weights['tfidf'] > 0.30, "TF-IDF should increase (many keep with high TF-IDF)"
    assert weights['frequency'] < 0.20, "Frequency should decrease (many drop with high frequency)"
    
    print(f"\nâœ… Adaptive learning working correctly!")
    print(f"   - TF-IDF increased (good for academic words)")
    print(f"   - Frequency decreased (causes noise with common words)")


def test_traceability():
    """Test BÆ¯á»šC 3.6: Traceability"""
    print("\n" + "=" * 80)
    print("TEST BÆ¯á»šC 3.6 - Traceability & Explainability")
    print("=" * 80)
    
    loop = FeedbackLoop(storage_path=TEST_DIR)
    memory = FeedbackMemory(TEST_DIR)
    
    # Load a feedback
    all_feedback = memory.load_all_feedback()
    if all_feedback:
        fb = all_feedback[0]
        
        print(f"âœ… Feedback traceability:")
        print(f"   Word: {fb.word}")
        print(f"   Action: {fb.user_action}")
        print(f"   Timestamp: {fb.timestamp}")
        print(f"   Weights used: {fb.weights_used}")
        print(f"   Scores: {fb.scores}")
        print(f"   Final score: {fb.final_score}")
        
        print(f"\nâœ… Can explain:")
        print(f"   - Why this word was extracted (scores)")
        print(f"   - What weights were used")
        print(f"   - When feedback was given")
        print(f"   - How it influenced future extractions")


def run_all_tests():
    """Run all tests"""
    print("\n" + "=" * 80)
    print("STAGE 3 - LEARNING FEEDBACK LOOP - COMPREHENSIVE TEST")
    print("=" * 80)
    
    # Clean up before starting
    cleanup_test_data()
    
    try:
        # Run tests in order
        test_feedback_collector()
        test_feedback_memory()
        test_feedback_analyzer()
        test_weight_adjuster()
        test_full_feedback_loop()
        test_traceability()
        
        print("\n" + "=" * 80)
        print("âœ… ALL TESTS PASSED!")
        print("=" * 80)
        
        # Checklist
        print("\nðŸ“‹ CHECKLIST - STAGE 3:")
        print("âœ… Há»‡ thá»‘ng thu tháº­p Ä‘Æ°á»£c pháº£n há»“i ngÆ°á»i há»c")
        print("âœ… Pháº£n há»“i Ä‘Æ°á»£c lÆ°u dÆ°á»›i dáº¡ng dá»¯ liá»‡u cÃ³ cáº¥u trÃºc")
        print("âœ… Trá»ng sá»‘ ensemble khÃ´ng cÃ²n cá»‘ Ä‘á»‹nh")
        print("âœ… TÃ i liá»‡u xá»­ lÃ½ sau cho káº¿t quáº£ tá»‘t hÆ¡n tÃ i liá»‡u trÆ°á»›c")
        print("âœ… Giáº£i thÃ­ch Ä‘Æ°á»£c vÃ¬ sao trá»ng sá»‘ thay Ä‘á»•i")
        print("âœ… KhÃ´ng sá»­ dá»¥ng mÃ´ hÃ¬nh ML huáº¥n luyá»‡n sáºµn")
        print("âœ… CÃ³ thá»ƒ mÃ´ táº£ Ä‘Ã¢y lÃ  adaptive learning system")
        print("\nðŸŽ¯ STAGE 3 Äáº T YÃŠU Cáº¦U: 7/7")
        
    finally:
        # Clean up after tests
        cleanup_test_data()
        if os.path.exists("ensemble_weights.json"):
            os.remove("ensemble_weights.json")


if __name__ == "__main__":
    run_all_tests()
