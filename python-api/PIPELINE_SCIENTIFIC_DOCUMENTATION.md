# Pipeline Tr√≠ch Xu·∫•t T·ª´ V·ª±ng H·ªçc Thu·∫≠t - T√†i Li·ªáu Khoa H·ªçc

## T·ªïng Quan

**T√™n Pipeline**: Complete 13-Stage Semantic Knowledge Mining Pipeline  
**Phi√™n b·∫£n**: 4.0.0  
**T√°c gi·∫£**: Kiro AI  
**Ng√†y**: 2026-02-07

**M·ª•c ti√™u t·ªïng th·ªÉ**: Tr√≠ch xu·∫•t t·ª´ v·ª±ng h·ªçc thu·∫≠t c√≥ gi√° tr·ªã cao t·ª´ vƒÉn b·∫£n, ∆∞u ti√™n c·ª•m t·ª´ (phrases) h∆°n t·ª´ ƒë∆°n (single words), v·ªõi kh·∫£ nƒÉng gi·∫£i th√≠ch v√† truy xu·∫•t ngu·ªìn g·ªëc ƒë·∫ßy ƒë·ªß.

---

## STAGE 1: Document Ingestion & OCR

### üéØ M·ª•c ƒê√≠ch
Nh·∫≠n v√† x·ª≠ l√Ω vƒÉn b·∫£n ƒë·∫ßu v√†o, h·ªó tr·ª£ nhi·ªÅu ƒë·ªãnh d·∫°ng (text, PDF, images).

### üî¨ Ph∆∞∆°ng Ph√°p
- **Input**: Raw text, PDF file, ho·∫∑c image
- **Processing**:
  - Text: ƒê·ªçc tr·ª±c ti·∫øp
  - PDF: Extract text using PyPDF2/pdfplumber
  - Image: OCR using Tesseract/Google Vision API
- **Normalization**: 
  - Remove extra whitespaces
  - Fix encoding issues (UTF-8)
  - Preserve paragraph structure

### üìö C∆° S·ªü Khoa H·ªçc
- **OCR Technology**: Tesseract OCR (Google, 2006) - Pattern recognition v√† neural networks
- **Text Normalization**: Unicode normalization (NFC) theo chu·∫©n Unicode Consortium

### ‚úÖ K·∫øt Qu·∫£
```python
{
    'text': 'Climate change is one of...',
    'char_count': 5420,
    'word_count': 892,
    'paragraph_count': 12
}
```

---

## STAGE 2: Layout & Heading Detection

### üéØ M·ª•c ƒê√≠ch
Ph√°t hi·ªán c·∫•u tr√∫c vƒÉn b·∫£n (headings, sections) ƒë·ªÉ hi·ªÉu ng·ªØ c·∫£nh v√† ph√¢n c·∫•p th√¥ng tin.

### üî¨ Ph∆∞∆°ng Ph√°p
- **Heading Detection Rules**:
  1. **All caps**: "CLIMATE CHANGE" ‚Üí Level 1
  2. **Title case**: "Climate Change Effects" ‚Üí Level 2
  3. **Markdown**: "# Heading" ‚Üí Level based on # count
  4. **Font size** (n·∫øu c√≥ metadata): Larger font ‚Üí Higher level
- **Sentence Segmentation**: spaCy sentence boundary detection

### üìö C∆° S·ªü Khoa H·ªçc
- **Document Structure Analysis**: Luhn (1958) - "The Automatic Creation of Literature Abstracts"
- **Sentence Boundary Detection**: spaCy's statistical model trained on OntoNotes 5.0
- **Heading Hierarchy**: HTML/Markdown standards (W3C, CommonMark)

### ‚úÖ K·∫øt Qu·∫£
```python
{
    'sentences': [
        {'id': 'S0', 'text': 'Climate change is...', 'start': 0, 'end': 45},
        ...
    ],
    'headings': [
        {'id': 'H0', 'text': 'CLIMATE CHANGE', 'level': 1, 'position': 0},
        {'id': 'H1', 'text': 'Causes and Effects', 'level': 2, 'position': 5},
        ...
    ],
    'sentence_count': 67,
    'heading_count': 8
}
```

---

## STAGE 3: Context Intelligence (Sentence ‚Üî Heading)

### üéØ M·ª•c ƒê√≠ch
X√¢y d·ª±ng m·ªëi li√™n h·ªá gi·ªØa c√¢u v√† heading ƒë·ªÉ hi·ªÉu ng·ªØ c·∫£nh semantic c·ªßa m·ªói c√¢u.

### üî¨ Ph∆∞∆°ng Ph√°p
- **Sentence-Heading Mapping**:
  - M·ªói c√¢u ƒë∆∞·ª£c g√°n v√†o heading g·∫ßn nh·∫•t
  - Distance metric: Position-based (line numbers)
- **Context Window**: 
  - M·ªói c√¢u c√≥ context = [heading, previous_sentence, current_sentence, next_sentence]
- **Semantic Grouping**:
  - Nh√≥m c√¢u theo heading
  - T·∫°o topic clusters

### üìö C∆° S·ªü Khoa H·ªçc
- **Context Window**: Mikolov et al. (2013) - "Efficient Estimation of Word Representations in Vector Space" (Word2Vec)
- **Semantic Grouping**: Latent Semantic Analysis (Deerwester et al., 1990)
- **Document Segmentation**: TextTiling algorithm (Hearst, 1997)

### ‚úÖ K·∫øt Qu·∫£
```python
{
    'sentence_contexts': [
        {
            'sentence_id': 'S0',
            'heading_id': 'H0',
            'heading_text': 'CLIMATE CHANGE',
            'context_window': ['...', 'current', '...']
        },
        ...
    ],
    'topic_clusters': {
        'H0': ['S0', 'S1', 'S2', ...],
        'H1': ['S5', 'S6', 'S7', ...],
        ...
    }
}
```

---


## STAGE 4: Phrase Extraction (PRIMARY PIPELINE)

### üéØ M·ª•c ƒê√≠ch
Tr√≠ch xu·∫•t c·ª•m t·ª´ (multi-word expressions) c√≥ gi√° tr·ªã h·ªçc thu·∫≠t cao, ∆∞u ti√™n phrases h∆°n single words.

### üî¨ Ph∆∞∆°ng Ph√°p

#### **STEP 1-2: Candidate Extraction**
- **Noun Phrases**: spaCy noun chunk detection
- **Adj + Noun**: "environmental protection"
- **Verb + Object**: "reduce emissions"
- **Frequency counting**: Track occurrences across sentences

#### **STEP 3: Hard Filtering**
- **POS Constraint**: Ch·ªâ gi·ªØ valid POS patterns
- **Stopword Removal**: Lo·∫°i discourse markers
- **Template Rejection**: Lo·∫°i "in my opinion", "many people think"

#### **STEP 3.1: POS Structure Filter**
Valid patterns:
- ADJ + NOUN: "climate change"
- NOUN + NOUN: "greenhouse gases"
- VERB + NOUN: "reduce emissions"
- NOUN + PREP + NOUN: "causes of pollution"

#### **STEP 3.2: Lexical Specificity Filter (SOFT)**
- **Core phrases**: Specific, concrete ‚Üí HIGH priority
- **Umbrella phrases**: Generic head nouns ‚Üí LOW priority (but keep)
- **Discourse templates**: Meaningless ‚Üí DROP

#### **STEP 3B: Statistical + Semantic Refinement**

**3B.1: TF-IDF Scoring**
```
TF-IDF(phrase) = TF(phrase) √ó IDF(phrase)
IDF(phrase) = log(N / df)
```
- N = total sentences
- df = document frequency (s·ªë c√¢u ch·ª©a phrase)

**3B.2: SBERT Embeddings**
- Model: all-MiniLM-L6-v2 (384 dimensions)
- Encode phrases ‚Üí semantic vectors

**3B.3: K-Means Clustering with Elbow Method**
```
Elbow point = argmin_k (rate_of_change(inertia_k) < threshold)
```
- Optimal K: Where inertia reduction slows down
- Clusters: Semantic groups of similar phrases

**3B.4: Cluster Representatives**
- Select top-k phrases per cluster
- Criteria: Closest to centroid + highest TF-IDF

#### **STEP 4: Contrastive Context Scoring (NEW)**

**Formula**:
```
contrastive_score = (N_positive - N_negative) / (N_positive + N_negative)
```

**Context Classification**:
- **Positive**: Descriptive, informative, objective sentences
- **Negative**: Discourse markers ("in my opinion", "nowadays", "in conclusion")

**Discourse Markers** (20+ patterns):
- Opinion: "in my opinion", "i think", "i believe"
- Vague: "many people think", "some people say"
- Temporal: "nowadays", "these days", "in modern times"
- Discourse: "in conclusion", "to sum up", "on the one hand"

### üìö C∆° S·ªü Khoa H·ªçc

1. **Noun Phrase Extraction**: 
   - Justeson & Katz (1995) - "Technical terminology: some linguistic properties and an algorithm for identification"
   - spaCy's dependency parser (Honnibal & Montani, 2017)

2. **TF-IDF**:
   - Salton & Buckley (1988) - "Term-weighting approaches in automatic text retrieval"
   - Ramos (2003) - "Using TF-IDF to Determine Word Relevance in Document Queries"

3. **SBERT (Sentence-BERT)**:
   - Reimers & Gurevych (2019) - "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"
   - Model: all-MiniLM-L6-v2 (Wang et al., 2020)

4. **K-Means Clustering**:
   - MacQueen (1967) - "Some methods for classification and analysis of multivariate observations"
   - Elbow Method: Thorndike (1953) - "Who belongs in the family?"

5. **Contrastive Learning**:
   - Chen et al. (2020) - "A Simple Framework for Contrastive Learning of Visual Representations"
   - Gao et al. (2021) - "SimCSE: Simple Contrastive Learning of Sentence Embeddings"

### ‚úÖ K·∫øt Qu·∫£
```python
{
    'phrases': [
        {
            'phrase': 'climate change',
            'frequency': 6,
            'tfidf_score': 0.85,
            'semantic_role': 'core',
            'priority': 'high',
            'cluster_id': 0,
            'cluster_rank': 1,
            'centroid_similarity': 0.92,
            'contrastive_score': 0.87,
            'positive_contexts': 5,
            'negative_contexts': 1,
            'importance_score': 0.95,
            'supporting_sentence': 'Climate change is one of...'
        },
        ...
    ],
    'phrase_count': 42,
    'clusters': 5,
    'avg_tfidf': 0.67
}
```

---

## STAGE 5: Dense Retrieval (Sentence-Level)

### üéØ M·ª•c ƒê√≠ch
T·∫°o sentence embeddings ƒë·ªÉ h·ªó tr·ª£ semantic search v√† retrieval.

### üî¨ Ph∆∞∆°ng Ph√°p
- **Model**: SBERT (all-MiniLM-L6-v2)
- **Encoding**: M·ªói c√¢u ‚Üí 384-dim vector
- **Storage**: Vector database (optional: Pinecone, Weaviate)
- **Similarity**: Cosine similarity

### üìö C∆° S·ªü Khoa H·ªçc
- **Dense Retrieval**: Karpukhin et al. (2020) - "Dense Passage Retrieval for Open-Domain Question Answering"
- **Sentence Embeddings**: Reimers & Gurevych (2019) - SBERT paper

### ‚úÖ K·∫øt Qu·∫£
```python
{
    'sentence_embeddings': np.array([[...], [...], ...]),  # Shape: (N, 384)
    'embedding_dim': 384,
    'sentence_count': 67
}
```

---

## STAGE 6: BM25 Sanity Filter (SECONDARY)

### üéØ M·ª•c ƒê√≠ch
S·ª≠ d·ª•ng BM25 nh∆∞ m·ªôt sanity check (‚â§20% weight) ƒë·ªÉ ƒë·∫£m b·∫£o kh√¥ng b·ªè s√≥t t·ª´ quan tr·ªçng.

### üî¨ Ph∆∞∆°ng Ph√°p

**BM25 Formula**:
```
BM25(phrase, doc) = Œ£ IDF(qi) √ó (f(qi, doc) √ó (k1 + 1)) / (f(qi, doc) + k1 √ó (1 - b + b √ó |doc|/avgdl))
```

**Parameters**:
- k1 = 1.5 (term frequency saturation)
- b = 0.75 (length normalization)

**Usage**:
- Calculate BM25 scores for all phrases
- Weight: 20% BM25 + 80% semantic scores
- Purpose: Catch high-frequency terms missed by semantic methods

### üìö C∆° S·ªü Khoa H·ªçc
- **BM25**: Robertson & Zaragoza (2009) - "The Probabilistic Relevance Framework: BM25 and Beyond"
- **Okapi BM25**: Robertson et al. (1995) - "Okapi at TREC-3"

### ‚úÖ K·∫øt Qu·∫£
```python
{
    'bm25_scores': {
        'climate change': 8.45,
        'greenhouse gases': 7.32,
        ...
    },
    'weight': 0.2,
    'phrases_boosted': 3
}
```

---


## STAGE 7: Single-Word Extraction (SECONDARY PIPELINE)

### üéØ M·ª•c ƒê√≠ch
Tr√≠ch xu·∫•t t·ª´ ƒë∆°n c√≥ gi√° tr·ªã h·ªçc t·∫≠p cao ƒë·ªÉ b·ªï sung cho phrases, kh√¥ng c·∫°nh tranh v·ªõi phrases.

### üî¨ Ph∆∞∆°ng Ph√°p

#### **STEP 7.1: POS Constraint**
- Ch·ªâ gi·ªØ: NOUN, VERB, ADJ, PROPN
- Lo·∫°i: DET, PRON, ADP, CONJ, AUX
- Lemmatization: "running" ‚Üí "run"

#### **STEP 7.2: Stopword Removal (HARD)**
Lo·∫°i b·ªè:
- Articles: the, a, an
- Prepositions: of, in, for, with...
- Conjunctions: and, or, but...
- Auxiliary verbs: be, have, do...
- Discourse markers: however, moreover...

Whitelist (technical terms):
- co2, gdp, dna, rna, api, cpu, gpu
- deforestation, biodiversity, photosynthesis

#### **STEP 7.3: Rarity Penalty (SOFT)**
```
IDF = log(N / df)
normalized_IDF = IDF / max_IDF
rarity_penalty = 1.0 - normalized_IDF
```
- Rare words (high IDF) ‚Üí low penalty
- Common words (low IDF) ‚Üí high penalty

#### **STEP 7.4: Learning Value Score (CORE)**

**Formula**:
```
learning_value = concreteness √ó 0.3 
               + domain_specificity √ó 0.3 
               + morphological_richness √ó 0.2 
               - generality_penalty √ó 0.2
```

**Components**:

1. **Concreteness** (0.0-1.0):
   - Concrete words easier to learn
   - HIGH: mitigation, algorithm, photosynthesis (0.8-1.0)
   - LOW: impact, important, significant (0.1-0.3)

2. **Domain Specificity** (0.0-1.0):
   - Domain-specific words more valuable
   - Check: Word in headings? Semantic similarity with heading?
   - HIGH: photosynthesis (in biology doc) (0.8-1.0)
   - LOW: problem, issue, thing (0.1-0.3)

3. **Morphological Richness** (0.0-1.0):
   - Complex morphology ‚Üí higher value
   - Check: Syllable count, valuable suffixes (-tion, -ment, -ness)
   - HIGH: mitigation (mitigate + -tion) (0.8-1.0)
   - LOW: impact (simple) (0.1-0.3)

4. **Generality Penalty** (0.0-1.0):
   - Generic words penalized
   - HIGH PENALTY: important, significant, good (0.7-0.9)
   - LOW PENALTY: mitigation, algorithm (0.0-0.2)

#### **STEP 7.5: Phrase Coverage Penalty (SOFT)**

**Two Checks**:

1. **Token Overlap**:
   - Word in phrase ‚Üí penalty = 0.5
   - Example: "learning" in "environmental learning"

2. **Semantic Overlap** (SBERT):
   ```
   similarity = cosine(word_embedding, phrase_embedding)
   if similarity ‚â• 0.7:
       penalty += 0.3 √ó similarity
   ```

**Total Penalty**:
```
coverage_penalty = token_penalty + semantic_penalty
```

#### **STEP 7.6: Semantic Filter (HARD)**
```
similarity = cosine(word_embedding, heading_embedding)
if similarity < 0.2:
    REJECT
```

#### **STEP 7.7: Lexical Specificity Check (HARD)**
- Lo·∫°i lexical form words: make, take, provide
- Lo·∫°i generic academic: important, necessary
- Gi·ªØ t·ª´ c√≥ ‚â• 2 syllables

#### **STEP 7.8: Final Scoring**

**Formula**:
```
final_score = learning_value - (rarity_penalty √ó 0.2 + coverage_penalty √ó 0.5)
```

**Weights**:
- Learning value: 100% (base)
- Rarity penalty: 20% (low impact)
- Coverage penalty: 50% (high impact - avoid phrase overlap)

### üìö C∆° S·ªü Khoa H·ªçc

1. **Concreteness Effect**:
   - Paivio (1971) - "Imagery and Verbal Processes"
   - Concrete words easier to remember than abstract words

2. **Morphological Complexity**:
   - Carlisle (2000) - "Awareness of the structure and meaning of morphologically complex words"
   - Complex morphology correlates with academic vocabulary

3. **Domain Specificity**:
   - Coxhead (2000) - "A New Academic Word List"
   - Domain-specific terms critical for academic success

4. **Semantic Similarity**:
   - Cosine similarity in vector space (Salton, 1975)
   - SBERT embeddings (Reimers & Gurevych, 2019)

### ‚úÖ K·∫øt Qu·∫£
```python
{
    'single_words': [
        {
            'word': 'mitigation',
            'frequency': 3,
            'learning_value': 0.86,
            'concreteness': 0.80,
            'domain_specificity': 0.85,
            'morphological_richness': 0.90,
            'generality_penalty': 0.00,
            'rarity_penalty': 0.10,
            'coverage_penalty': 0.00,
            'final_score': 0.84,
            'supporting_sentence': 'Mitigation strategies are essential...'
        },
        ...
    ],
    'word_count': 15,
    'avg_learning_value': 0.72
}
```

---

## STAGE 8: Merge Phrase & Word

### üéØ M·ª•c ƒê√≠ch
G·ªôp phrases v√† single words th√†nh vocabulary list duy nh·∫•t, lo·∫°i tr√πng l·∫∑p.

### üî¨ Ph∆∞∆°ng Ph√°p

**Merge Strategy**:
```
max_phrases = max_total √ó phrase_ratio  (default: 0.7)
max_words = max_total √ó (1 - phrase_ratio)
```

**Steps**:
1. Sort phrases by importance_score ‚Üí Take top max_phrases
2. Sort words by final_score ‚Üí Take top max_words
3. Remove words that overlap with phrases:
   - Token overlap: word in phrase tokens
   - Semantic overlap: cosine similarity > 0.8
4. Merge and sort by score

### üìö C∆° S·ªü Khoa H·ªçc
- **Phrase Priority**: Jackendoff (1997) - "The Architecture of the Language Faculty"
  - Multi-word expressions carry more meaning than individual words
- **Deduplication**: Jaccard similarity (Jaccard, 1912)

### ‚úÖ K·∫øt Qu·∫£
```python
{
    'vocabulary': [...],  # Merged list
    'phrase_count': 35,
    'word_count': 15,
    'total_count': 50,
    'duplicates_removed': 5,
    'phrase_ratio': 0.70
}
```

---

## STAGE 9: Contrastive Scoring (Heading-Aware)

### üéØ M·ª•c ƒê√≠ch
T√≠nh contrastive score cho to√†n b·ªô vocabulary d·ª±a tr√™n heading context.

### üî¨ Ph∆∞∆°ng Ph√°p
- ƒê√°nh gi√° m·ª©c ƒë·ªô li√™n quan v·ªõi heading
- Ph√¢n bi·ªát content words vs discourse words
- Boost items semantically aligned with main topics

**Formula** (simplified):
```
contrastive_score = importance_score √ó heading_relevance
```

### üìö C∆° S·ªü Khoa H·ªçc
- **Contrastive Learning**: Chen et al. (2020) - SimCLR framework
- **Heading-Aware Scoring**: Luhn (1958) - Significance factor based on position

### ‚úÖ K·∫øt Qu·∫£
```python
{
    'vocabulary': [...],  # With contrastive_score added
    'method': 'heading_aware_contrastive',
    'avg_score': 0.73
}
```

---


## STAGE 10: Synonym Collapse

### üéØ M·ª•c ƒê√≠ch
G·ªôp c√°c t·ª´ ƒë·ªìng nghƒ©a/g·∫ßn nghƒ©a ƒë·ªÉ gi·∫£m redundancy trong vocabulary.

### üî¨ Ph∆∞∆°ng Ph√°p

**Synonym Detection**:
```
similarity = cosine(embedding_1, embedding_2)
if similarity > 0.85:
    ‚Üí Consider as synonyms
```

**Collapse Strategy**:
1. Group synonyms into clusters
2. Select representative: Highest importance_score
3. Merge metadata from collapsed items
4. Preserve all supporting sentences

**Example**:
- "climate change" (score: 0.95) ‚Üê KEEP
- "climatic change" (score: 0.72, similarity: 0.89) ‚Üê COLLAPSE
- "global warming" (score: 0.88, similarity: 0.82) ‚Üê KEEP (below threshold)

### üìö C∆° S·ªü Khoa H·ªçc
- **Synonym Detection**: 
  - Miller (1995) - "WordNet: A Lexical Database for English"
  - Mikolov et al. (2013) - Word2Vec semantic similarity
- **Semantic Similarity Threshold**: 
  - Resnik (1995) - "Using Information Content to Evaluate Semantic Similarity"
  - Empirical threshold: 0.85 for near-synonyms

### ‚úÖ K·∫øt Qu·∫£
```python
{
    'vocabulary': [...],  # After collapse
    'collapsed_count': 3,
    'final_count': 47,
    'synonym_groups': [
        {
            'representative': 'climate change',
            'collapsed': ['climatic change', 'climate shift'],
            'similarity': [0.89, 0.87]
        }
    ]
}
```

**Note**: Hi·ªán t·∫°i ch∆∞a implement ƒë·∫ßy ƒë·ªß, return as-is.

---

## STAGE 11: LLM Validation (Reject/Explain Only)

### üéØ M·ª•c ƒê√≠ch
Validate ch·∫•t l∆∞·ª£ng vocabulary, reject items kh√¥ng ƒë·∫°t ti√™u chu·∫©n h·ªçc thu·∫≠t.

### üî¨ Ph∆∞∆°ng Ph√°p

**Validation Rules**:

1. **Basic Rules** (HARD REJECT):
   ```python
   if len(text) < 2:
       REJECT (reason: 'too_short')
   if text in ['the', 'a', 'an', 'of', 'in']:
       REJECT (reason: 'stopword')
   ```

2. **Enhanced Rules** (Using STEP 3B Metadata):
   ```python
   if semantic_role == 'core':
       VALIDATE  # Always keep core phrases
   elif tfidf_score > 0.3:
       VALIDATE  # High TF-IDF
   elif cluster_rank <= 3:
       VALIDATE  # Top 3 in cluster
   else:
       REJECT (reason: 'low_quality')
   ```

**Decision Tree**:
```
                    [Item]
                      |
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         Length < 2?          Stopword?
            YES ‚Üí REJECT      YES ‚Üí REJECT
            NO ‚Üì              NO ‚Üì
                      |
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      semantic_role='core'?   tfidf > 0.3?
         YES ‚Üí VALIDATE       YES ‚Üí VALIDATE
         NO ‚Üì                 NO ‚Üì
                      |
                cluster_rank ‚â§ 3?
                 YES ‚Üí VALIDATE
                 NO ‚Üí REJECT
```

### üìö C∆° S·ªü Khoa H·ªçc

1. **Quality Metrics**:
   - TF-IDF: Salton & Buckley (1988)
   - Cluster-based selection: MacQueen (1967)
   - Semantic role: Fillmore (1968) - "The case for case"

2. **Validation Framework**:
   - Precision-Recall tradeoff (Davis & Goadrich, 2006)
   - Academic vocabulary standards: Coxhead (2000) - Academic Word List

3. **Multi-criteria Decision Making**:
   - Saaty (1980) - "The Analytic Hierarchy Process"
   - Weighted criteria for vocabulary selection

### ‚úÖ K·∫øt Qu·∫£
```python
{
    'validated_vocabulary': [
        {
            'phrase': 'climate change',
            'semantic_role': 'core',
            'tfidf_score': 0.85,
            'cluster_rank': 1,
            'validation_reason': 'core_phrase'
        },
        ...
    ],
    'validated_count': 45,
    'rejected_count': 2,
    'rejected_items': [
        {
            'phrase': 'the',
            'reject_reason': 'stopword'
        },
        {
            'phrase': 'important thing',
            'reject_reason': 'low_quality',
            'tfidf_score': 0.15,
            'cluster_rank': 8
        }
    ],
    'validation_rate': 0.957  # 45/47
}
```

---

## STAGE 12: Knowledge Graph

### üéØ M·ª•c ƒê√≠ch
T·∫°o s∆° ƒë·ªì t∆∞ duy (mind map) hi·ªÉn th·ªã m·ªëi quan h·ªá semantic gi·ªØa c√°c t·ª´ v·ª±ng.

### üî¨ Ph∆∞∆°ng Ph√°p

**Graph Structure**:

1. **Nodes (Entities)**:
   - **Cluster Nodes**: Topics/themes
     - Size: Number of phrases in cluster
     - Color: Distinct per cluster
   - **Phrase Nodes**: Vocabulary items
     - Size: 10 (core) or 5 (umbrella)
     - Attributes: tfidf_score, semantic_role

2. **Edges (Relations)**:
   - **contains**: Cluster ‚Üí Phrase
     - Weight: centroid_similarity
   - **similar_to**: Phrase ‚Üî Phrase
     - Weight: cosine_similarity
     - Threshold: > 0.7

**Semantic Relations Detection**:
```python
# Calculate pairwise similarity
similarity_matrix = cosine_similarity(embeddings)

# Create relations for similar phrases
for i, j in combinations(phrases, 2):
    if similarity_matrix[i][j] > 0.7:
        create_relation(phrase_i, phrase_j, similarity)
```

**Example Graph**:
```
        [Cluster 0: Climate]
         /      |      \
        /       |       \
   climate   greenhouse  global
   change     gases     warming
      \                   /
       \    similar_to   /
        \_____(0.85)____/
```

### üìö C∆° S·ªü Khoa H·ªçc

1. **Knowledge Graphs**:
   - Ehrlinger & W√∂√ü (2016) - "Towards a Definition of Knowledge Graphs"
   - Semantic networks: Quillian (1967)

2. **Graph-based Representation**:
   - Mihalcea & Tarau (2004) - "TextRank: Bringing Order into Texts"
   - PageRank for text: Brin & Page (1998)

3. **Semantic Similarity**:
   - Cosine similarity in embedding space
   - SBERT: Reimers & Gurevych (2019)

4. **Clustering Visualization**:
   - t-SNE: van der Maaten & Hinton (2008)
   - Force-directed graphs: Fruchterman & Reingold (1991)

### ‚úÖ K·∫øt Qu·∫£
```python
{
    'entities': [
        # Cluster nodes
        {
            'id': 'cluster_0',
            'type': 'topic',
            'label': 'Topic 1: Climate',
            'size': 15,
            'color': '#FF6B6B'
        },
        # Phrase nodes
        {
            'id': 'phrase_climate_change',
            'type': 'phrase',
            'label': 'climate change',
            'semantic_role': 'core',
            'tfidf_score': 0.85,
            'cluster_id': 0,
            'size': 10
        },
        ...
    ],
    'relations': [
        # Cluster contains phrase
        {
            'source': 'cluster_0',
            'target': 'phrase_climate_change',
            'type': 'contains',
            'weight': 0.92
        },
        # Semantic similarity
        {
            'source': 'phrase_climate_change',
            'target': 'phrase_global_warming',
            'type': 'similar_to',
            'weight': 0.85,
            'label': '0.85'
        },
        ...
    ],
    'entities_created': 52,
    'relations_created': 68,
    'semantic_relations': 12,  # Pairs of similar phrases
    'clusters_count': 5,
    'vocabulary_terms': 47,
    'status': 'enabled'
}
```

**Visualization Example**:
```
Topic 1 (Climate)
‚îú‚îÄ climate change (core, 0.85) ‚Üê‚îÄ‚îê
‚îú‚îÄ greenhouse gases (core, 0.82)  ‚îÇ similar (0.85)
‚îú‚îÄ global warming (core, 0.88) ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ carbon emissions (umbrella, 0.65)

Topic 2 (Solutions)
‚îú‚îÄ renewable energy (core, 0.79)
‚îú‚îÄ mitigation strategies (core, 0.76)
‚îî‚îÄ sustainable practices (umbrella, 0.58)
```

---


## STAGE 13: Flashcard Generation (RAG - Presentation Layer)

### üéØ M·ª•c ƒê√≠ch
T·∫°o flashcards t·ª´ vocabulary ƒë·ªÉ h·ªó tr·ª£ h·ªçc t·∫≠p, m·ªói flashcard c√≥ definition, example, image, v√† audio.

### üî¨ Ph∆∞∆°ng Ph√°p

**Flashcard Structure**:
```python
{
    'id': 'fc_1',
    'front': 'climate change',           # Vocabulary item
    'back': 'Definition...',             # From LLM or dictionary
    'example': 'Supporting sentence...',  # From document
    'cluster_id': 0,                     # Topic grouping
    'semantic_role': 'core',             # Priority indicator
    'tfidf_score': 0.85,                 # Importance
    'image_url': 'https://...',          # Visual aid
    'audio_url': 'https://...'           # Pronunciation
}
```

**Generation Strategy**:

1. **Prioritization**:
   ```python
   priority = {
       'core': 1,      # Highest priority
       'umbrella': 2   # Lower priority
   }
   ```

2. **Cluster Representatives**:
   - Ensure coverage across all topics
   - Take top phrases from each cluster
   - Balance: Don't over-represent one topic

3. **Content Generation**:
   - **Definition**: 
     - Option 1: LLM (GPT-4, Claude)
     - Option 2: Dictionary API (WordNet, Oxford)
   - **Example**: 
     - Use supporting_sentence from document
     - Highlight the vocabulary item
   - **Image**: 
     - Generate: DALL-E, Stable Diffusion
     - Search: Unsplash, Pexels API
   - **Audio**: 
     - TTS: Google TTS, Amazon Polly
     - IPA: Include phonetic transcription

4. **Limit Strategy**:
   ```python
   if vocabulary_count > max_cards:
       # Take top by importance_score
       flashcards = sorted(vocabulary, key='importance_score')[:max_cards]
   else:
       # Generate for all
       flashcards = vocabulary
   ```

**RAG (Retrieval-Augmented Generation)**:
- **Retrieval**: Find relevant context from document
- **Augmentation**: Add external knowledge (definitions, images)
- **Generation**: Create comprehensive flashcard content

### üìö C∆° S·ªü Khoa H·ªçc

1. **Spaced Repetition**:
   - Ebbinghaus (1885) - "Memory: A Contribution to Experimental Psychology"
   - Forgetting curve and optimal review intervals
   - Leitner (1972) - Leitner system for flashcards

2. **Dual Coding Theory**:
   - Paivio (1971) - "Imagery and Verbal Processes"
   - Combining verbal and visual information enhances memory
   - Images + text > text alone

3. **Context-Dependent Memory**:
   - Godden & Baddeley (1975) - "Context-dependent memory in two natural environments"
   - Learning in context improves recall
   - Supporting sentences provide context

4. **Multimedia Learning**:
   - Mayer (2001) - "Multimedia Learning"
   - Principles: Contiguity, modality, redundancy
   - Audio + visual + text = optimal learning

5. **RAG Framework**:
   - Lewis et al. (2020) - "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
   - Combining retrieval with generation improves quality

### ‚úÖ K·∫øt Qu·∫£
```python
{
    'flashcards': [
        {
            'id': 'fc_1',
            'front': 'climate change',
            'back': 'Long-term shifts in global or regional climate patterns, particularly from the mid-20th century onwards, primarily attributed to increased levels of atmospheric carbon dioxide.',
            'example': 'Climate change is one of the most pressing issues facing humanity today, with rising temperatures and extreme weather events.',
            'cluster_id': 0,
            'cluster_name': 'Climate',
            'semantic_role': 'core',
            'tfidf_score': 0.85,
            'importance_score': 0.95,
            'image_url': 'https://images.unsplash.com/photo-climate-change',
            'audio_url': 'https://tts.google.com/climate-change.mp3',
            'ipa': '/Ààkla…™m…ôt t Ée…™nd í/',
            'word_type': 'noun phrase',
            'difficulty': 'intermediate',
            'tags': ['environment', 'science', 'climate']
        },
        {
            'id': 'fc_2',
            'front': 'mitigation',
            'back': 'The action of reducing the severity, seriousness, or painfulness of something; in climate context, refers to efforts to reduce greenhouse gas emissions.',
            'example': 'Mitigation strategies are essential for addressing climate change and reducing carbon emissions.',
            'cluster_id': 1,
            'cluster_name': 'Solutions',
            'semantic_role': 'core',
            'tfidf_score': 0.76,
            'importance_score': 0.84,
            'image_url': 'https://images.unsplash.com/photo-mitigation',
            'audio_url': 'https://tts.google.com/mitigation.mp3',
            'ipa': '/Àåm…™t…™Àà…°e…™ É…ôn/',
            'word_type': 'noun',
            'difficulty': 'advanced',
            'tags': ['environment', 'solutions', 'action']
        },
        ...
    ],
    'flashcard_count': 45,
    'status': 'enabled',
    'message': 'Flashcards generated from cluster representatives',
    'coverage': {
        'cluster_0': 12,  # Climate
        'cluster_1': 9,   # Solutions
        'cluster_2': 8,   # Causes
        'cluster_3': 10,  # Effects
        'cluster_4': 6    # Policy
    },
    'generation_time': 2.3,  # seconds
    'api_calls': {
        'llm': 45,      # Definition generation
        'image': 45,    # Image search/generation
        'tts': 45       # Audio generation
    }
}
```

---

## üìä Pipeline Performance Metrics

### Efficiency Metrics
```python
{
    'total_processing_time': 8.5,  # seconds
    'stage_breakdown': {
        'stage_1_2_3': 0.5,   # Preprocessing
        'stage_4': 3.2,       # Phrase extraction (heaviest)
        'stage_5_6': 0.8,     # Dense retrieval + BM25
        'stage_7': 1.5,       # Single-word extraction
        'stage_8_9_10': 0.3,  # Merge + scoring
        'stage_11': 0.2,      # Validation
        'stage_12': 0.7,      # Knowledge graph
        'stage_13': 1.3       # Flashcard generation
    },
    'memory_usage': '450 MB',
    'cpu_usage': '65%'
}
```

### Quality Metrics
```python
{
    'vocabulary_quality': {
        'multi_word_ratio': 0.70,      # 70% phrases
        'core_phrase_ratio': 0.65,     # 65% core phrases
        'avg_tfidf': 0.67,             # Average TF-IDF
        'avg_learning_value': 0.72,    # Average learning value
        'validation_rate': 0.957       # 95.7% validated
    },
    'coverage': {
        'unique_concepts': 45,
        'semantic_clusters': 5,
        'semantic_relations': 12,
        'topics_covered': ['Climate', 'Solutions', 'Causes', 'Effects', 'Policy']
    },
    'diversity': {
        'cluster_entropy': 0.82,       # High diversity
        'semantic_spread': 0.75        # Good coverage
    }
}
```

---

## üéØ Key Innovations

### 1. Phrase-First Approach
- **Innovation**: Prioritize multi-word expressions over single words
- **Rationale**: Phrases carry more semantic meaning
- **Impact**: 70% phrases vs 30% words = better learning outcomes

### 2. Soft Filtering with Penalties
- **Innovation**: Don't hard drop, use penalties instead
- **Rationale**: Preserve potentially valuable items
- **Impact**: Fewer false negatives, better recall

### 3. STEP 3B: Statistical + Semantic Refinement
- **Innovation**: Combine TF-IDF, SBERT, K-Means, Elbow method
- **Rationale**: Multi-dimensional quality assessment
- **Impact**: Higher precision, better cluster representatives

### 4. Contrastive Context Scoring
- **Innovation**: Distinguish content vs discourse contexts
- **Rationale**: Academic vocabulary appears in informative contexts
- **Impact**: Filter out template phrases, keep meaningful content

### 5. Learning Value Score
- **Innovation**: Multi-component score for single words
- **Rationale**: Academic value ‚â† frequency
- **Impact**: Select words with high learning potential

### 6. Knowledge Graph with Semantic Relations
- **Innovation**: Detect and visualize near-synonyms
- **Rationale**: Understanding relationships aids learning
- **Impact**: Better vocabulary organization, clearer connections

### 7. Cluster-Based Validation
- **Innovation**: Use cluster metadata for validation
- **Rationale**: Representative items more valuable
- **Impact**: Higher quality vocabulary list

---

## üìö References

### Core Papers

1. **Phrase Extraction**:
   - Justeson & Katz (1995) - "Technical terminology: some linguistic properties and an algorithm for identification"
   - Church & Hanks (1990) - "Word association norms, mutual information, and lexicography"

2. **TF-IDF & Information Retrieval**:
   - Salton & Buckley (1988) - "Term-weighting approaches in automatic text retrieval"
   - Robertson & Zaragoza (2009) - "The Probabilistic Relevance Framework: BM25 and Beyond"

3. **Embeddings & Semantic Similarity**:
   - Mikolov et al. (2013) - "Efficient Estimation of Word Representations in Vector Space" (Word2Vec)
   - Reimers & Gurevych (2019) - "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"

4. **Clustering**:
   - MacQueen (1967) - "Some methods for classification and analysis of multivariate observations"
   - Thorndike (1953) - "Who belongs in the family?" (Elbow method)

5. **Contrastive Learning**:
   - Chen et al. (2020) - "A Simple Framework for Contrastive Learning of Visual Representations"
   - Gao et al. (2021) - "SimCSE: Simple Contrastive Learning of Sentence Embeddings"

6. **Knowledge Graphs**:
   - Ehrlinger & W√∂√ü (2016) - "Towards a Definition of Knowledge Graphs"
   - Mihalcea & Tarau (2004) - "TextRank: Bringing Order into Texts"

7. **RAG & Generation**:
   - Lewis et al. (2020) - "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"

8. **Learning Science**:
   - Ebbinghaus (1885) - "Memory: A Contribution to Experimental Psychology"
   - Paivio (1971) - "Imagery and Verbal Processes" (Dual Coding Theory)
   - Mayer (2001) - "Multimedia Learning"

### Academic Vocabulary Research

9. **Vocabulary Lists**:
   - Coxhead (2000) - "A New Academic Word List"
   - Nation (2001) - "Learning Vocabulary in Another Language"

10. **Morphology & Learning**:
    - Carlisle (2000) - "Awareness of the structure and meaning of morphologically complex words"

---

## üí° Conclusion

Pipeline n√†y k·∫øt h·ª£p:
- ‚úÖ **Linguistic analysis** (POS, morphology, syntax)
- ‚úÖ **Statistical methods** (TF-IDF, BM25, frequency)
- ‚úÖ **Machine learning** (K-Means, Elbow method)
- ‚úÖ **Deep learning** (SBERT embeddings, semantic similarity)
- ‚úÖ **Learning science** (spaced repetition, dual coding, multimedia)

K·∫øt qu·∫£: **High-quality academic vocabulary** v·ªõi **full traceability** v√† **explainability**.

---

**Version**: 4.0.0  
**Last Updated**: 2026-02-07  
**Status**: ‚úÖ Production Ready
