import { NextRequest, NextResponse } from "next/server";
import { OpenAI } from 'openai';
import { connectToDatabase } from '@/lib/mongodb';
import { 
  generateSLASystemPrompt, 
  generateRecast, 
  getEncouragement,
  shouldCorrect,
  LearnerProfile,
  SLAConfig 
} from '@/lib/slaSystemPrompt';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// Default learner profile (can be customized per user)
const DEFAULT_LEARNER_PROFILE: LearnerProfile = {
  level: 'A2',
  nativeLanguage: 'English',
  learningGoals: ['Giao ti·∫øp h√†ng ng√†y', 'Du l·ªãch Vi·ªát Nam'],
  weakAreas: ['D·∫•u thanh', 'Ng·ªØ ph√°p'],
  strongAreas: ['T·ª´ v·ª±ng c∆° b·∫£n'],
  conversationCount: 0,
  lastTopics: []
};

// SLA Configuration
const SLA_CONFIG: SLAConfig = {
  enableRecasting: true,
  enableIPlusOne: true,
  enableAffectiveFilter: true,
  feedbackStyle: 'implicit',
  correctionFrequency: 'sometimes'
};

// Intent classification system
const INTENT_CATEGORIES = {
  GRAMMAR_CHECK: 'grammar_check',
  VOCABULARY_HELP: 'vocabulary_help',
  TRANSLATION: 'translation',
  CONVERSATION: 'conversation',
  LEARNING_GUIDANCE: 'learning_guidance',
  DOCUMENT_SEARCH: 'document_search',
  PRONUNCIATION: 'pronunciation',
  CULTURAL_INFO: 'cultural_info'
};

interface ChatMessage {
  role: 'user' | 'assistant' | 'system';
  content: string;
}

interface IntentAnalysis {
  intent: string;
  confidence: number;
  entities: string[];
  needsDocumentSearch: boolean;
  needsGrammarCheck: boolean;
}

interface GrammarCorrection {
  hasErrors: boolean;
  original: string;
  corrected: string;
  errors: Array<{
    type: string;
    position: number;
    original: string;
    corrected: string;
    explanation: string;
  }>;
  explanation: string;
}

interface DataSourceAnalysis {
  userDocumentPercentage: number;
  externalSourcePercentage: number;
  totalDocumentsFound: number;
  totalVocabularyFound: number;
  sourceBreakdown: {
    userDocuments: number;
    userVocabulary: number;
    aiKnowledge: number;
  };
}

interface BilingualResponse {
  vietnamese: string;
  english: string;
  isTranslated: boolean;
}

// Analyze user intent using AI
async function analyzeIntent(userMessage: string): Promise<IntentAnalysis> {
  try {
    const prompt = `
Ph√¢n t√≠ch √Ω ƒë·ªãnh c·ªßa ng∆∞·ªùi d√πng trong tin nh·∫Øn ti·∫øng Vi·ªát sau:

TIN NH·∫ÆN: "${userMessage}"

H√£y x√°c ƒë·ªãnh:
1. √ù ƒë·ªãnh ch√≠nh (intent)
2. ƒê·ªô tin c·∫≠y (0-100)
3. C√°c th·ª±c th·ªÉ quan tr·ªçng (entities)
4. C√≥ c·∫ßn t√¨m ki·∫øm t√†i li·ªáu kh√¥ng?
5. C√≥ c·∫ßn ki·ªÉm tra ng·ªØ ph√°p kh√¥ng?

C√ÅC LO·∫†I √ù ƒê·ªäNH:
- grammar_check: Ki·ªÉm tra/s·ª≠a l·ªói ng·ªØ ph√°p
- vocabulary_help: H·ªèi v·ªÅ t·ª´ v·ª±ng, nghƒ©a t·ª´
- translation: D·ªãch thu·∫≠t
- conversation: Tr√≤ chuy·ªán th√¥ng th∆∞·ªùng
- learning_guidance: H∆∞·ªõng d·∫´n h·ªçc t·∫≠p
- document_search: T√¨m ki·∫øm th√¥ng tin trong t√†i li·ªáu
- pronunciation: Ph√°t √¢m
- cultural_info: Th√¥ng tin vƒÉn h√≥a

ƒê·ªäNH D·∫†NG JSON:
{
  "intent": "intent_name",
  "confidence": 85,
  "entities": ["entity1", "entity2"],
  "needsDocumentSearch": true/false,
  "needsGrammarCheck": true/false
}`;

    const response = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [
        {
          role: "system",
          content: "B·∫°n l√† chuy√™n gia ph√¢n t√≠ch √Ω ƒë·ªãnh ng∆∞·ªùi d√πng. Lu√¥n tr·∫£ v·ªÅ JSON h·ª£p l·ªá."
        },
        {
          role: "user",
          content: prompt
        }
      ],
      temperature: 0.3,
      max_tokens: 300,
    });

    const content = response.choices[0]?.message?.content;
    if (content) {
      const jsonMatch = content.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        return JSON.parse(jsonMatch[0]);
      }
    }

    // Fallback intent analysis
    return {
      intent: INTENT_CATEGORIES.CONVERSATION,
      confidence: 50,
      entities: [],
      needsDocumentSearch: false,
      needsGrammarCheck: true
    };

  } catch (error) {
    console.error('Intent analysis error:', error);
    return {
      intent: INTENT_CATEGORIES.CONVERSATION,
      confidence: 30,
      entities: [],
      needsDocumentSearch: false,
      needsGrammarCheck: true
    };
  }
}

// Advanced grammar checking with detailed explanations
async function checkGrammarAdvanced(text: string): Promise<GrammarCorrection> {
  try {
    const prompt = `
B·∫°n l√† chuy√™n gia ng·ªØ ph√°p ti·∫øng Vi·ªát. H√£y ki·ªÉm tra v√† s·ª≠a l·ªói trong c√¢u sau:

C√ÇU G·ªêC: "${text}"

H√£y ph√¢n t√≠ch:
1. C√≥ l·ªói ng·ªØ ph√°p kh√¥ng?
2. L·ªói g√¨? (d·∫•u thanh, ch√≠nh t·∫£, ng·ªØ ph√°p, t·ª´ v·ª±ng)
3. V·ªã tr√≠ l·ªói ·ªü ƒë√¢u?
4. S·ª≠a nh∆∞ th·∫ø n√†o?
5. Gi·∫£i th√≠ch t·∫°i sao?

ƒê·ªäNH D·∫†NG JSON:
{
  "hasErrors": true/false,
  "original": "c√¢u g·ªëc",
  "corrected": "c√¢u ƒë√£ s·ª≠a",
  "errors": [
    {
      "type": "tone_mark/spelling/grammar/vocabulary",
      "position": 5,
      "original": "t·ª´ sai",
      "corrected": "t·ª´ ƒë√∫ng", 
      "explanation": "gi·∫£i th√≠ch chi ti·∫øt"
    }
  ],
  "explanation": "t·ªïng quan v·ªÅ c√°c l·ªói"
}

N·∫øu kh√¥ng c√≥ l·ªói, tr·∫£ v·ªÅ hasErrors: false.`;

    const response = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [
        {
          role: "system",
          content: "B·∫°n l√† chuy√™n gia ng·ªØ ph√°p ti·∫øng Vi·ªát. Lu√¥n tr·∫£ v·ªÅ JSON h·ª£p l·ªá."
        },
        {
          role: "user",
          content: prompt
        }
      ],
      temperature: 0.1,
      max_tokens: 500,
    });

    const content = response.choices[0]?.message?.content;
    if (content) {
      const jsonMatch = content.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        return JSON.parse(jsonMatch[0]);
      }
    }

    return {
      hasErrors: false,
      original: text,
      corrected: text,
      errors: [],
      explanation: "Kh√¥ng ph√°t hi·ªán l·ªói ng·ªØ ph√°p."
    };

  } catch (error) {
    console.error('Grammar check error:', error);
    return {
      hasErrors: false,
      original: text,
      corrected: text,
      errors: [],
      explanation: "Kh√¥ng th·ªÉ ki·ªÉm tra ng·ªØ ph√°p l√∫c n√†y."
    };
  }
}

// Enhanced search with data source analysis
async function searchDocumentsWithAnalysis(query: string, entities: string[]): Promise<{
  results: string[];
  sourceAnalysis: DataSourceAnalysis;
}> {
  try {
    const { db } = await connectToDatabase();
    
    // Search in documents collection
    const searchTerms = [query, ...entities].filter(Boolean);
    const searchRegex = new RegExp(searchTerms.join('|'), 'i');
    
    const documents = await db.collection('documents')
      .find({
        $or: [
          { fileName: searchRegex },
          { extractedText: searchRegex }
        ]
      })
      .limit(5)
      .toArray();

    // Search in vocabulary collection
    const vocabularies = await db.collection('vocabularies')
      .find({
        $or: [
          { word: searchRegex },
          { meaning: searchRegex },
          { example: searchRegex }
        ]
      })
      .limit(10)
      .toArray();

    const results = [];
    
    // Add document excerpts
    for (const doc of documents) {
      if (doc.extractedText) {
        const excerpt = doc.extractedText.substring(0, 200) + '...';
        results.push(`üìÑ T·ª´ t√†i li·ªáu "${doc.fileName}": ${excerpt}`);
      }
    }

    // Add vocabulary entries
    for (const vocab of vocabularies) {
      results.push(`üìö T·ª´ v·ª±ng: ${vocab.word} - ${vocab.meaning}\nV√≠ d·ª•: ${vocab.example}`);
    }

    // Calculate data source percentages
    const totalUserData = documents.length + vocabularies.length;
    const userDocumentPercentage = totalUserData > 0 ? Math.round((totalUserData / (totalUserData + 1)) * 100) : 0;
    const externalSourcePercentage = 100 - userDocumentPercentage;

    const sourceAnalysis: DataSourceAnalysis = {
      userDocumentPercentage,
      externalSourcePercentage,
      totalDocumentsFound: documents.length,
      totalVocabularyFound: vocabularies.length,
      sourceBreakdown: {
        userDocuments: documents.length,
        userVocabulary: vocabularies.length,
        aiKnowledge: userDocumentPercentage < 50 ? 1 : 0
      }
    };

    return { results, sourceAnalysis };

  } catch (error) {
    console.error('Document search error:', error);
    return {
      results: [],
      sourceAnalysis: {
        userDocumentPercentage: 0,
        externalSourcePercentage: 100,
        totalDocumentsFound: 0,
        totalVocabularyFound: 0,
        sourceBreakdown: {
          userDocuments: 0,
          userVocabulary: 0,
          aiKnowledge: 1
        }
      }
    };
  }
}

// Generate bilingual translation
async function generateBilingualResponse(vietnameseText: string): Promise<BilingualResponse> {
  try {
    const prompt = `
D·ªãch c√¢u ti·∫øng Vi·ªát sau sang ti·∫øng Anh m·ªôt c√°ch t·ª± nhi√™n v√† ch√≠nh x√°c:

TI·∫æNG VI·ªÜT: "${vietnameseText}"

Y√™u c·∫ßu:
1. D·ªãch t·ª± nhi√™n, kh√¥ng m√°y m√≥c
2. Gi·ªØ nguy√™n √Ω nghƒ©a v√† ng·ªØ c·∫£nh
3. S·ª≠ d·ª•ng t·ª´ v·ª±ng ph√π h·ª£p

ƒê·ªäNH D·∫†NG JSON:
{
  "vietnamese": "c√¢u ti·∫øng Vi·ªát g·ªëc",
  "english": "c√¢u ti·∫øng Anh ƒë√£ d·ªãch",
  "isTranslated": true
}`;

    const response = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [
        {
          role: "system",
          content: "B·∫°n l√† chuy√™n gia d·ªãch thu·∫≠t Vi·ªát-Anh. Lu√¥n tr·∫£ v·ªÅ JSON h·ª£p l·ªá."
        },
        {
          role: "user",
          content: prompt
        }
      ],
      temperature: 0.3,
      max_tokens: 400,
    });

    const content = response.choices[0]?.message?.content;
    if (content) {
      const jsonMatch = content.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        return JSON.parse(jsonMatch[0]);
      }
    }

    return {
      vietnamese: vietnameseText,
      english: "Translation not available",
      isTranslated: false
    };

  } catch (error) {
    console.error('Translation error:', error);
    return {
      vietnamese: vietnameseText,
      english: "Translation not available",
      isTranslated: false
    };
  }
}

// Generate intelligent response based on intent with SLA principles
async function generateSmartResponse(
  userMessage: string,
  intent: IntentAnalysis,
  grammarCheck: GrammarCorrection,
  documentResults: string[],
  sourceAnalysis: DataSourceAnalysis,
  conversationHistory: ChatMessage[],
  learnerProfile: LearnerProfile = DEFAULT_LEARNER_PROFILE
): Promise<{ response: string; recastUsed: boolean; encouragement: string }> {
  try {
    // Generate SLA-based system prompt
    const slaSystemPrompt = generateSLASystemPrompt(learnerProfile, SLA_CONFIG);
    
    // Build context-aware prompt
    let contextPrompt = `
${slaSystemPrompt}

---
## CURRENT CONVERSATION CONTEXT

**User Intent**: ${intent.intent} (${intent.confidence}% confidence)
**Entities**: ${intent.entities.join(', ') || 'None detected'}
`;

    // Handle grammar errors with RECASTING (not direct correction)
    let recastUsed = false;
    if (grammarCheck.hasErrors && SLA_CONFIG.enableRecasting) {
      const shouldRecast = shouldCorrect(SLA_CONFIG.correctionFrequency, grammarCheck.errors.length);
      
      if (shouldRecast) {
        recastUsed = true;
        contextPrompt += `
**RECASTING REQUIRED**:
- Original: "${grammarCheck.original}"
- Correct form: "${grammarCheck.corrected}"
- Error types: ${grammarCheck.errors.map(e => e.type).join(', ')}

‚ö†Ô∏è IMPORTANT: Use RECASTING technique!
- Do NOT say "B·∫°n n√≥i sai" or "L·ªói ng·ªØ ph√°p"
- Instead, naturally include the correct form in your response
- Example recast: "${generateRecast('grammar', grammarCheck.original, grammarCheck.corrected)}"
`;
      }
    }

    // Add document context if available
    if (documentResults.length > 0) {
      contextPrompt += `
**RELEVANT DOCUMENTS** (${sourceAnalysis.totalDocumentsFound} found):
${documentResults.slice(0, 3).join('\n')}

Use this information to provide personalized responses.
`;
    }

    // Add i+1 instruction
    if (SLA_CONFIG.enableIPlusOne) {
      contextPrompt += `
**i+1 INSTRUCTION**:
- Current level: ${learnerProfile.level}
- Introduce 1-2 new vocabulary/structures
- Keep within comprehensible range
- Provide context clues for new items
`;
    }

    // Add affective filter instruction
    const encouragement = getEncouragement(grammarCheck.hasErrors ? 'effort' : 'success');
    if (SLA_CONFIG.enableAffectiveFilter) {
      contextPrompt += `
**AFFECTIVE FILTER**:
- Start with encouragement: "${encouragement}"
- Keep tone warm and supportive
- Make learner feel comfortable making mistakes
`;
    }

    const messages: ChatMessage[] = [
      { role: 'system', content: contextPrompt },
      ...conversationHistory.slice(-6), // Keep last 6 messages for context
      { role: 'user', content: userMessage }
    ];

    const response = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: messages,
      temperature: 0.7,
      max_tokens: 800,
    });

    const aiResponse = response.choices[0]?.message?.content;
    if (!aiResponse) {
      throw new Error("No response from OpenAI");
    }
    return { response: aiResponse, recastUsed, encouragement };

  } catch (error) {
    console.error('Response generation error:', error);
    
    // SLA-based fallback with recasting
    const encouragement = getEncouragement('effort');
    let fallbackResponse = '';
    
    switch (intent.intent) {
      case INTENT_CATEGORIES.GRAMMAR_CHECK:
        if (grammarCheck.hasErrors) {
          // Use recasting instead of direct correction
          const recast = generateRecast('grammar', grammarCheck.original, grammarCheck.corrected);
          fallbackResponse = `${encouragement} ${recast} B·∫°n mu·ªën n√≥i th√™m g√¨ kh√¥ng?`;
        } else {
          fallbackResponse = `${encouragement} C√¢u c·ªßa b·∫°n r·∫•t t·ªët! H√£y ti·∫øp t·ª•c nh√©! üí™`;
        }
        break;
        
      case INTENT_CATEGORIES.VOCABULARY_HELP:
        fallbackResponse = `${encouragement} T√¥i hi·ªÉu b·∫°n mu·ªën h·ªçc t·ª´ v·ª±ng! B·∫°n mu·ªën h·ªçc v·ªÅ ch·ªß ƒë·ªÅ g√¨? T√¥i c√≥ th·ªÉ gi√∫p b·∫°n v·ªõi:\n\nüçú Th·ª©c ƒÉn\nüë®‚Äçüë©‚Äçüëß Gia ƒë√¨nh\nüè† Nh√† c·ª≠a\nüöó Giao th√¥ng`;
        break;
        
      case INTENT_CATEGORIES.TRANSLATION:
        fallbackResponse = `${encouragement} T√¥i s·∫µn s√†ng gi√∫p b·∫°n d·ªãch! H√£y vi·∫øt c√¢u c·∫ßn d·ªãch nh√©. üåê`;
        break;
        
      case INTENT_CATEGORIES.DOCUMENT_SEARCH:
        if (documentResults.length > 0) {
          fallbackResponse = `${encouragement} T√¥i t√¨m th·∫•y ${documentResults.length} t√†i li·ªáu li√™n quan! B·∫°n mu·ªën xem kh√¥ng?`;
        } else {
          fallbackResponse = `${encouragement} T√¥i ch∆∞a t√¨m th·∫•y t√†i li·ªáu ph√π h·ª£p. B·∫°n c√≥ th·ªÉ th·ª≠ t·ª´ kh√≥a kh√°c kh√¥ng?`;
        }
        break;
        
      default:
        fallbackResponse = `${encouragement} Xin ch√†o! T√¥i l√† Viet-Talk AI - tr·ª£ l√Ω h·ªçc ti·∫øng Vi·ªát c·ªßa b·∫°n! üáªüá≥\n\nH√¥m nay b·∫°n mu·ªën:\nüí¨ Tr√≤ chuy·ªán ti·∫øng Vi·ªát\nüìö H·ªçc t·ª´ v·ª±ng m·ªõi\nüéØ Luy·ªán ph√°t √¢m\n\nB·∫°n ch·ªçn g√¨?`;
    }
    
    return { response: fallbackResponse, recastUsed: false, encouragement };
  }
}

export async function POST(req: NextRequest) {
  try {
    const { message, conversationHistory = [] } = await req.json();

    if (!message || typeof message !== 'string') {
      return NextResponse.json(
        { success: false, message: "Message is required" },
        { status: 400 }
      );
    }

    // Step 1: Analyze user intent
    const intentAnalysis = await analyzeIntent(message);

    // Step 2: Check grammar if needed
    let grammarCheck: GrammarCorrection = {
      hasErrors: false,
      original: message,
      corrected: message,
      errors: [],
      explanation: ""
    };

    if (intentAnalysis.needsGrammarCheck) {
      grammarCheck = await checkGrammarAdvanced(message);
    }

    // Step 3: Search documents if needed
    let documentResults: string[] = [];
    let sourceAnalysis: DataSourceAnalysis = {
      userDocumentPercentage: 0,
      externalSourcePercentage: 100,
      totalDocumentsFound: 0,
      totalVocabularyFound: 0,
      sourceBreakdown: {
        userDocuments: 0,
        userVocabulary: 0,
        aiKnowledge: 1
      }
    };

    if (intentAnalysis.needsDocumentSearch) {
      const searchResult = await searchDocumentsWithAnalysis(message, intentAnalysis.entities);
      documentResults = searchResult.results;
      sourceAnalysis = searchResult.sourceAnalysis;
    }

    // Step 4: Generate intelligent response with SLA principles
    const { response: aiResponse, recastUsed, encouragement } = await generateSmartResponse(
      message,
      intentAnalysis,
      grammarCheck,
      documentResults,
      sourceAnalysis,
      conversationHistory
    );

    // Step 5: Generate bilingual translation
    const bilingualResponse = await generateBilingualResponse(aiResponse);

    return NextResponse.json({
      success: true,
      response: aiResponse,
      bilingualResponse,
      sourceAnalysis,
      intent: intentAnalysis,
      grammarCheck: grammarCheck.hasErrors ? grammarCheck : null,
      documentResults: documentResults.length > 0 ? documentResults : null,
      // SLA-specific metadata
      slaMetadata: {
        recastUsed,
        encouragement,
        learnerLevel: DEFAULT_LEARNER_PROFILE.level,
        feedbackStyle: SLA_CONFIG.feedbackStyle,
        iPlusOneEnabled: SLA_CONFIG.enableIPlusOne
      },
      metadata: {
        hasGrammarErrors: grammarCheck.hasErrors,
        foundDocuments: documentResults.length,
        confidence: intentAnalysis.confidence,
        userDataPercentage: sourceAnalysis.userDocumentPercentage,
        aiDataPercentage: sourceAnalysis.externalSourcePercentage
      }
    });

  } catch (error) {
    console.error("Smart chat error:", error);
    return NextResponse.json(
      { success: false, message: "Chat processing failed" },
      { status: 500 }
    );
  }
}

export async function GET(req: NextRequest) {
  return NextResponse.json({
    success: true,
    message: "Smart Chat API is running",
    features: [
      "Intent Analysis",
      "Advanced Grammar Checking", 
      "Document Search",
      "Context-Aware Responses",
      "Multi-language Support"
    ]
  });
}